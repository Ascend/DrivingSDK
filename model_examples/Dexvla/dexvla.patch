diff --git a/qwen2_vla/models/modeling_qwen2_vla.py b/qwen2_vla/models/modeling_qwen2_vla.py
index e47fe3d..ae397eb 100644
--- a/qwen2_vla/models/modeling_qwen2_vla.py
+++ b/qwen2_vla/models/modeling_qwen2_vla.py
@@ -24,6 +24,7 @@ from dataclasses import dataclass
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import torch
+import torch_npu
 import torch.nn as nn
 import torch.nn.functional as F
 import torch.utils.checkpoint
@@ -292,6 +293,8 @@ class PatchEmbed(nn.Module):
         hidden_states = hidden_states.view(
             -1, self.in_channels, self.temporal_patch_size, self.patch_size, self.patch_size
         )
+        import torch_npu
+        hidden_states = torch_npu.npu_format_cast(hidden_states, 30)
         hidden_states = self.proj(hidden_states.to(dtype=target_dtype)).view(-1, self.embed_dim)
         return hidden_states
 
@@ -374,9 +377,19 @@ class VisionFlashAttention2(nn.Module):
         k = apply_rotary_pos_emb_vision(k.unsqueeze(0), rotary_pos_emb).squeeze(0)
 
         max_seqlen = (cu_seqlens[1:] - cu_seqlens[:-1]).max().item()
-        attn_output = flash_attn_varlen_func(q, k, v, cu_seqlens, cu_seqlens, max_seqlen, max_seqlen).reshape(
-            seq_length, -1
-        )
+        head_num = q.shape[1]
+        attn_output = torch_npu.npu_fusion_attention(
+             q, k, v, head_num,
+             pse=None,
+             atten_mask=None,
+             scale=1.0 / math.sqrt(q.shape[-1]),
+             keep_prob=1,
+             input_layout="TND",
+             actual_seq_qlen=tuple(cu_seqlens[1:].cpu().numpy().tolist()),
+             actual_seq_kvlen=tuple(cu_seqlens[1:].cpu().numpy().tolist()))[0].reshape(seq_length, -1)
+        #attn_output = flash_attn_varlen_func(q, k, v, cu_seqlens, cu_seqlens, max_seqlen, max_seqlen).reshape(
+        #    seq_length, -1
+        #)
         attn_output = self.proj(attn_output)
         return attn_output
 
@@ -410,7 +423,7 @@ class VisionSdpaAttention(nn.Module):
 
 
 QWEN2_VL_VISION_ATTENTION_CLASSES = {
-    "eager": VisionAttention,
+    "eager": VisionFlashAttention2,
     "flash_attention_2": VisionFlashAttention2,
     "sdpa": VisionSdpaAttention,
 }
diff --git a/requirements.txt b/requirements.txt
index 0bf8db9..d88add9 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -27,8 +27,6 @@ colorama==0.3.0
 contourpy==1.1.1
 cycler==0.12.1
 decorator==5.1.1
-decord==0.6.0
-deepspeed==0.9.5
 diffusers==0.11.1
 distro==1.9.0
 dm-control==1.0.14
@@ -79,7 +77,6 @@ jsonschema==4.21.1
 jsonschema-specifications==2023.12.1
 kiwisolver==1.4.5
 labmaze==1.0.6
-liger_kernel==0.3.1
 linkify-it-py==2.0.3
 lit==18.1.3
 llvmlite==0.41.1
@@ -100,29 +97,6 @@ ninja==1.11.1.1
 numba==0.58.1
 numcodecs==0.12.1
 numpy==1.24.4
-nvidia-cublas-cu11==11.10.3.66
-nvidia-cublas-cu12==12.1.3.1
-nvidia-cuda-cupti-cu11==11.7.101
-nvidia-cuda-cupti-cu12==12.1.105
-nvidia-cuda-nvrtc-cu11==11.7.99
-nvidia-cuda-nvrtc-cu12==12.1.105
-nvidia-cuda-runtime-cu11==11.7.99
-nvidia-cuda-runtime-cu12==12.1.105
-nvidia-cudnn-cu11==8.5.0.96
-nvidia-cudnn-cu12==9.1.0.70
-nvidia-cufft-cu11==10.9.0.58
-nvidia-cufft-cu12==11.0.2.54
-nvidia-curand-cu11==10.2.10.91
-nvidia-curand-cu12==10.3.2.106
-nvidia-cusolver-cu11==11.4.0.1
-nvidia-cusolver-cu12==11.4.5.107
-nvidia-cusparse-cu11==11.7.4.91
-nvidia-cusparse-cu12==12.1.0.106
-nvidia-nccl-cu11==2.14.3
-nvidia-nccl-cu12==2.20.5
-nvidia-nvjitlink-cu12==12.6.77
-nvidia-nvtx-cu11==11.7.91
-nvidia-nvtx-cu12==12.1.105
 oauthlib==3.2.2
 opencv-python==4.10.0.84
 orjson==3.10.1
@@ -194,12 +168,10 @@ tianshou==0.4.10
 timm==0.9.10
 tokenizers==0.20.1
 toolz==0.12.1
-torch==2.4.1
-torchvision==0.15.2
+torchvision==0.16.0
 tqdm==4.66.5
 traitlets==5.14.3
 transformers==4.45.2
-triton==3.0.0
 typing_extensions==4.11.0
 tzdata==2024.1
 uc-micro-py==1.0.3
diff --git a/scripts/train_dexvla_stage2.sh b/scripts/train_dexvla_stage2.sh
index 3f6236c..bdfbc57 100755
--- a/scripts/train_dexvla_stage2.sh
+++ b/scripts/train_dexvla_stage2.sh
@@ -3,21 +3,25 @@ LLM=qwen2_vl
 LLM_MODEL_SIZE=2B
 
 ACTION_HEAD=scale_dp_policy  #unet_diffusion_policy or scale_dp_policy
+qwen=$1
+dit_pretrain=$2
+output=$3
+num_step=$4
 
-DIT_PRETRAIN=/path/to/pretrained/ScaleDP
-MNOP=/path/to/pretrained/qwen2_vl # official qwen2_vl weights
+DIT_PRETRAIN=$dit_pretrain
+MNOP=$qwen # official qwen2_vl weights
 
 TASKNAME=example_tasks
 
-OUTPUT=/path/to/save/dir
+OUTPUT=$output
 
-deepspeed --master_port 29604 --num_gpus=8 --num_nodes=1 ./train_vla.py \
+OMP_NUM_THREADS=1 MKL_NUM_THREADS=1 deepspeed --master_port 29604 --num_gpus=8  --num_nodes=1 ./train_vla.py \
   --deepspeed scripts/zero2.json \
   --use_reasoning True \
   --lora_enable False \
   --action_dim 14 \
   --state_dim 14 \
-  --flash_attn True \
+  --flash_attn False \
   --chunk_size 50 \
   --load_pretrain_dit True \
   --pretrain_dit_path $DIT_PRETRAIN \
@@ -36,7 +40,7 @@ deepspeed --master_port 29604 --num_gpus=8 --num_nodes=1 ./train_vla.py \
   --image_aspect_ratio pad \
   --bf16 True \
   --output_dir $OUTPUT \
-  --max_steps 100000 \
+  --max_steps $num_step \
   --per_device_train_batch_size 12 \
   --gradient_accumulation_steps 1 \
   --save_strategy "steps" \
@@ -46,8 +50,8 @@ deepspeed --master_port 29604 --num_gpus=8 --num_nodes=1 ./train_vla.py \
   --weight_decay 0. \
   --warmup_ratio 0.01 \
   --lr_scheduler_type "constant" \
-  --logging_steps 50 \
-  --tf32 True \
+  --logging_steps 5 \
+  --tf32 False \
   --model_max_length 2048 \
   --gradient_checkpointing True \
   --dataloader_num_workers 8 \
diff --git a/scripts/train_dexvla_stage3.sh b/scripts/train_dexvla_stage3.sh
index cf7bf9f..f69bdb6 100755
--- a/scripts/train_dexvla_stage3.sh
+++ b/scripts/train_dexvla_stage3.sh
@@ -4,19 +4,24 @@ LLM_MODEL_SIZE=2B
 
 ACTION_HEAD=scale_dp_policy  #unet_diffusion_policy or scale_dp_policy
 
-DIT_PRETRAIN=/path/to/pretrained/ScaleDP
-MNOP=/path/to/trained/DexVLA # DexVLA weights after stage 2
+stage1_weights=$1
+stage2_output=$2
+stage3_output=$3
+num_step=$4
+
+DIT_PRETRAIN=$stage1_weights
+MNOP=$stage2_output # DexVLA weights after stage 2
 TASKNAME=example_tasks
 
-OUTPUT=/path/to/save/dir
+OUTPUT=$stage3_output
 
-deepspeed --master_port 29604 --num_gpus=8 --num_nodes=1 ./train_vla.py \
+OMP_NUM_THREADS=1 MKL_NUM_THREADS=1 deepspeed --master_port 29604 --num_gpus=8 --num_nodes=1 ./train_vla.py \
   --deepspeed scripts/zero2.json \
   --use_reasoning True \
   --lora_enable False \
   --action_dim 14 \
   --state_dim 14 \
-  --flash_attn True \
+  --flash_attn False \
   --chunk_size 50 \
   --lora_module "vit llm" \
   --using_film True \
@@ -38,7 +43,7 @@ deepspeed --master_port 29604 --num_gpus=8 --num_nodes=1 ./train_vla.py \
   --group_by_modality_length False \
   --bf16 True \
   --output_dir $OUTPUT \
-  --max_steps 80000 \
+  --max_steps $num_step \
   --per_device_train_batch_size 12 \
   --gradient_accumulation_steps 1 \
   --save_strategy "steps" \
@@ -49,7 +54,7 @@ deepspeed --master_port 29604 --num_gpus=8 --num_nodes=1 ./train_vla.py \
   --warmup_ratio 0.001 \
   --lr_scheduler_type "cosine" \
-  --logging_steps 50 \
-  --tf32 True \
+  --logging_steps 5 \
+  --tf32 False \
   --model_max_length 2048 \
   --gradient_checkpointing True \
   --dataloader_num_workers 8 \
@@ -67,4 +72,4 @@ for dir in "$OUTPUT"/*/ ; do
 done
 
 mv ./60030.log $OUTPUT
-echo $OUTPUT
\ No newline at end of file
+echo $OUTPUT
diff --git a/train_vla.py b/train_vla.py
index 1d4bb3a..19478ba 100644
--- a/train_vla.py
+++ b/train_vla.py
@@ -3,7 +3,8 @@ import pickle
 
 import os
 import time
-
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 os.environ["TOKENIZERS_PARALLELISM"] = "false"
 
 os.environ['DEVICE'] = "cuda"
@@ -306,6 +307,9 @@ def main(all_config=None, model_config=None):
         None. The trained model and statistics are saved to the output directory
         specified in training_args.
     """
+    torch_npu.npu.set_compile_mode(jit_compile=False)
+    torch_npu.npu.config.allow_internal_format = False
+
     set_seed(1)
     task_config = TASK_CONFIGS[all_config['data_args'].task_name]
     dataset_dir = task_config['dataset_dir']

