diff --git a/projects/configs/flashocc/flashocc-r50-perf.py b/projects/configs/flashocc/flashocc-r50-perf.py
new file mode 100644
index 0000000..c4bac01
--- /dev/null
+++ b/projects/configs/flashocc/flashocc-r50-perf.py
@@ -0,0 +1,268 @@
+_base_ = ['../../../mmdetection3d/configs/_base_/datasets/nus-3d.py',
+          '../../../mmdetection3d/configs/_base_/default_runtime.py']
+
+plugin = True
+plugin_dir = 'projects/mmdet3d_plugin/'
+point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
+# For nuScenes we usually do 10-class detection
+class_names = [
+    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
+    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
+]
+
+data_config = {
+    'cams': [
+        'CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT',
+        'CAM_BACK', 'CAM_BACK_RIGHT'
+    ],
+    'Ncams':
+    6,
+    'input_size': (256, 704),
+    'src_size': (900, 1600),
+
+    # Augmentation
+    'resize': (-0.06, 0.11),
+    'rot': (-5.4, 5.4),
+    'flip': True,
+    'crop_h': (0.0, 0.0),
+    'resize_test': 0.00,
+}
+
+grid_config = {
+    'x': [-40, 40, 0.4],
+    'y': [-40, 40, 0.4],
+    'z': [-1, 5.4, 6.4],
+    'depth': [1.0, 45.0, 0.5],
+}
+
+voxel_size = [0.1, 0.1, 0.2]
+
+numC_Trans = 64
+
+model = dict(
+    type='BEVDetOCC',
+    img_backbone=dict(
+        type='ResNet',
+        depth=50,
+        num_stages=4,
+        out_indices=(2, 3),
+        frozen_stages=-1,
+        norm_cfg=dict(type='BN', requires_grad=True),
+        norm_eval=False,
+        with_cp=True,
+        style='pytorch',
+        pretrained='torchvision://resnet50',
+    ),
+    img_neck=dict(
+        type='CustomFPN',
+        in_channels=[1024, 2048],
+        out_channels=256,
+        num_outs=1,
+        start_level=0,
+        out_ids=[0]),
+    img_view_transformer=dict(
+        type='LSSViewTransformer',
+        grid_config=grid_config,
+        input_size=data_config['input_size'],
+        in_channels=256,
+        out_channels=numC_Trans,
+        sid=False,
+        collapse_z=True,
+        downsample=16),
+    img_bev_encoder_backbone=dict(
+        type='CustomResNet',
+        numC_input=numC_Trans,
+        num_channels=[numC_Trans * 2, numC_Trans * 4, numC_Trans * 8]),
+    img_bev_encoder_neck=dict(
+        type='FPN_LSS',
+        in_channels=numC_Trans * 8 + numC_Trans * 2,
+        out_channels=256),
+    occ_head=dict(
+        type='BEVOCCHead2D',
+        in_dim=256,
+        out_dim=256,    # out_dim=128 for M0!!!
+        Dz=16,
+        use_mask=True,
+        num_classes=18,
+        use_predicter=True,
+        class_balance=False,
+        loss_occ=dict(
+            type='CrossEntropyLoss',
+            use_sigmoid=False,
+            ignore_index=255,
+            loss_weight=1.0
+        ),
+    )
+)
+
+# Data
+dataset_type = 'NuScenesDatasetOccpancy'
+data_root = 'data/nuscenes/'
+file_client_args = dict(backend='disk')
+
+bda_aug_conf = dict(
+    rot_lim=(-0., 0.),
+    scale_lim=(1., 1.),
+    flip_dx_ratio=0.5,
+    flip_dy_ratio=0.5
+)
+
+train_pipeline = [
+    dict(
+        type='PrepareImageInputs',
+        is_train=True,
+        data_config=data_config,
+        sequential=False),
+    dict(
+        type='LoadAnnotationsBEVDepth',
+        bda_aug_conf=bda_aug_conf,
+        classes=class_names,
+        is_train=True),
+    dict(type='LoadOccGTFromFile'),
+    dict(
+        type='LoadPointsFromFile',
+        coord_type='LIDAR',
+        load_dim=5,
+        use_dim=5,
+        file_client_args=file_client_args),
+    dict(type='PointToMultiViewDepth', downsample=1, grid_config=grid_config),
+    dict(type='DefaultFormatBundle3D', class_names=class_names),
+    dict(
+        type='Collect3D', keys=['img_inputs', 'gt_depth', 'voxel_semantics',
+                                'mask_lidar', 'mask_camera'])
+]
+
+test_pipeline = [
+    dict(type='PrepareImageInputs', data_config=data_config, sequential=False),
+    dict(
+        type='LoadAnnotationsBEVDepth',
+        bda_aug_conf=bda_aug_conf,
+        classes=class_names,
+        is_train=False),
+    dict(
+        type='LoadPointsFromFile',
+        coord_type='LIDAR',
+        load_dim=5,
+        use_dim=5,
+        file_client_args=file_client_args),
+    dict(
+        type='MultiScaleFlipAug3D',
+        img_scale=(1333, 800),
+        pts_scale_ratio=1,
+        flip=False,
+        transforms=[
+            dict(
+                type='DefaultFormatBundle3D',
+                class_names=class_names,
+                with_label=False),
+            dict(type='Collect3D', keys=['points', 'img_inputs'])
+        ])
+]
+
+
+input_modality = dict(
+    use_lidar=False,
+    use_camera=True,
+    use_radar=False,
+    use_map=False,
+    use_external=False)
+
+share_data_config = dict(
+    type=dataset_type,
+    data_root=data_root,
+    classes=class_names,
+    modality=input_modality,
+    stereo=False,
+    filter_empty_gt=False,
+    img_info_prototype='bevdet',
+)
+
+test_data_config = dict(
+    pipeline=test_pipeline,
+    ann_file=data_root + 'bevdetv2-nuscenes_infos_val.pkl')
+
+data = dict(
+    samples_per_gpu=24,
+    workers_per_gpu=4,
+    train=dict(
+        data_root=data_root,
+        ann_file=data_root + 'bevdetv2-nuscenes_infos_train.pkl',
+        pipeline=train_pipeline,
+        classes=class_names,
+        test_mode=False,
+        use_valid_flag=True,
+        # we use box_type_3d='LiDAR' in kitti and nuscenes dataset
+        # and box_type_3d='Depth' in sunrgbd and scannet dataset.
+        box_type_3d='LiDAR'),
+    val=test_data_config,
+    test=test_data_config)
+
+for key in ['val', 'train', 'test']:
+    data[key].update(share_data_config)
+
+# Optimizer
+optimizer = dict(type='NpuFusedAdamW', lr=2.45*1e-4, weight_decay=1e-2)
+optimizer_config = dict(grad_clip=dict(max_norm=5, norm_type=2))
+lr_config = dict(
+    policy='step',
+    warmup='linear',
+    warmup_iters=200,
+    warmup_ratio=0.001,
+    step=[24, ])
+runner = dict(type='EpochBasedRunner', max_epochs=1)
+
+custom_hooks = [
+    dict(
+        type='MEGVIIEMAHook',
+        init_updates=10560,
+        priority='NORMAL',
+    ),
+]
+
+load_from = "ckpts/bevdet-r50-cbgs.pth"
+# fp16 = dict(loss_scale='dynamic')
+evaluation = dict(interval=1, start=20, pipeline=test_pipeline)
+checkpoint_config = dict(interval=1, max_keep_ckpts=5)
+
+
+# with det pretrain; use_mask=True;
+# ===> per class IoU of 6019 samples:
+# ===> others - IoU = 6.74
+# ===> barrier - IoU = 37.65
+# ===> bicycle - IoU = 10.26
+# ===> bus - IoU = 39.55
+# ===> car - IoU = 44.36
+# ===> construction_vehicle - IoU = 14.88
+# ===> motorcycle - IoU = 13.4
+# ===> pedestrian - IoU = 15.79
+# ===> traffic_cone - IoU = 15.38
+# ===> trailer - IoU = 27.44
+# ===> truck - IoU = 31.73
+# ===> driveable_surface - IoU = 78.82
+# ===> other_flat - IoU = 37.98
+# ===> sidewalk - IoU = 48.7
+# ===> terrain - IoU = 52.5
+# ===> manmade - IoU = 37.89
+# ===> vegetation - IoU = 32.24
+# ===> mIoU of 6019 samples: 32.08
+
+# with det pretrain; use_mask=False; class_balance=True
+# ===> per class IoU of 6019 samples:
+# ===> others - IoU = 4.49
+# ===> barrier - IoU = 29.59
+# ===> bicycle - IoU = 7.38
+# ===> bus - IoU = 30.32
+# ===> car - IoU = 32.22
+# ===> construction_vehicle - IoU = 13.04
+# ===> motorcycle - IoU = 11.91
+# ===> pedestrian - IoU = 8.61
+# ===> traffic_cone - IoU = 8.11
+# ===> trailer - IoU = 7.66
+# ===> truck - IoU = 20.84
+# ===> driveable_surface - IoU = 48.59
+# ===> other_flat - IoU = 26.62
+# ===> sidewalk - IoU = 26.08
+# ===> terrain - IoU = 20.86
+# ===> manmade - IoU = 7.62
+# ===> vegetation - IoU = 7.14
+# ===> mIoU of 6019 samples: 18.3
\ No newline at end of file
diff --git a/projects/configs/flashocc/flashocc-r50.py b/projects/configs/flashocc/flashocc-r50.py
index ff4d67f..7ad0a44 100644
--- a/projects/configs/flashocc/flashocc-r50.py
+++ b/projects/configs/flashocc/flashocc-r50.py
@@ -182,7 +182,7 @@ test_data_config = dict(
     ann_file=data_root + 'bevdetv2-nuscenes_infos_val.pkl')
 
 data = dict(
-    samples_per_gpu=4,
+    samples_per_gpu=24,
     workers_per_gpu=4,
     train=dict(
         data_root=data_root,
@@ -201,7 +201,7 @@ for key in ['val', 'train', 'test']:
     data[key].update(share_data_config)
 
 # Optimizer
-optimizer = dict(type='AdamW', lr=1e-4, weight_decay=1e-2)
+optimizer = dict(type='NpuFusedAdamW', lr=2.45*1e-4, weight_decay=1e-2)
 optimizer_config = dict(grad_clip=dict(max_norm=5, norm_type=2))
 lr_config = dict(
     policy='step',
diff --git a/projects/configs/flashocc/flashocc-stbase-4d-stereo-512x1408_4x4_2e-4.py b/projects/configs/flashocc/flashocc-stbase-4d-stereo-512x1408_4x4_2e-4.py
index 3785cd1..c01f9a9 100644
--- a/projects/configs/flashocc/flashocc-stbase-4d-stereo-512x1408_4x4_2e-4.py
+++ b/projects/configs/flashocc/flashocc-stbase-4d-stereo-512x1408_4x4_2e-4.py
@@ -114,7 +114,7 @@ model = dict(
         use_mask=True,
         num_classes=18,
         use_predicter=True,
-        class_wise=False,
+        class_balance=False,
         loss_occ=dict(
             type='CrossEntropyLoss',
             use_sigmoid=False,
@@ -229,7 +229,7 @@ for key in ['val', 'train', 'test']:
     data[key].update(share_data_config)
 
 # Optimizer
-optimizer = dict(type='AdamW', lr=2e-4, weight_decay=1e-2)
+optimizer = dict(type='NpuFusedAdamW', lr=2e-4, weight_decay=1e-2)
 optimizer_config = dict(grad_clip=dict(max_norm=5, norm_type=2))
 lr_config = dict(
     policy='step',
diff --git a/projects/mmdet3d_plugin/core/evaluation/ray_metrics.py b/projects/mmdet3d_plugin/core/evaluation/ray_metrics.py
index e90f7bf..f40770a 100644
--- a/projects/mmdet3d_plugin/core/evaluation/ray_metrics.py
+++ b/projects/mmdet3d_plugin/core/evaluation/ray_metrics.py
@@ -10,7 +10,7 @@ from prettytable import PrettyTable
 from .ray_pq import Metric_RayPQ
 
 
-dvr = load("dvr", sources=["lib/dvr/dvr.cpp", "lib/dvr/dvr.cu"], verbose=True, extra_cuda_cflags=['-allow-unsupported-compiler'])
+# dvr = load("dvr", sources=["lib/dvr/dvr.cpp", "lib/dvr/dvr.cu"], verbose=True, extra_cuda_cflags=['-allow-unsupported-compiler'])
 _pc_range = [-40, -40, -1.0, 40, 40, 5.4]
 _voxel_size = 0.4
 
diff --git a/projects/mmdet3d_plugin/models/detectors/bevdet.py b/projects/mmdet3d_plugin/models/detectors/bevdet.py
index 2e40982..209280e 100644
--- a/projects/mmdet3d_plugin/models/detectors/bevdet.py
+++ b/projects/mmdet3d_plugin/models/detectors/bevdet.py
@@ -69,10 +69,9 @@ class BEVDet(CenterPoint):
 
         # calculate the transformation from adj sensor to key ego
         keyego2global = ego2globals[:, 0,  ...].unsqueeze(1)    # (B, 1, 4, 4)
-        global2keyego = torch.inverse(keyego2global.double())   # (B, 1, 4, 4)
+        global2keyego = torch.inverse(keyego2global)   # (B, 1, 4, 4)
         sensor2keyegos = \
-            global2keyego @ ego2globals.double() @ sensor2egos.double()     # (B, N_views, 4, 4)
-        sensor2keyegos = sensor2keyegos.float()
+            global2keyego @ ego2globals @ sensor2egos     # (B, N_views, 4, 4)
 
         return [imgs, sensor2keyegos, ego2globals, intrins,
                 post_rots, post_trans, bda]
diff --git a/projects/mmdet3d_plugin/models/necks/view_transformer.py b/projects/mmdet3d_plugin/models/necks/view_transformer.py
index 0ab03f4..be70ccc 100644
--- a/projects/mmdet3d_plugin/models/necks/view_transformer.py
+++ b/projects/mmdet3d_plugin/models/necks/view_transformer.py
@@ -3,10 +3,10 @@ import torch
 import torch.nn as nn
 from mmcv.runner import BaseModule, force_fp32
 from mmdet3d.models.builder import NECKS
-from ...ops import bev_pool_v2
 from ..model_utils import DepthNet
 from torch.cuda.amp.autocast_mode import autocast
 import torch.nn.functional as F
+from mx_driving import bev_pool_v3
 
 
 @NECKS.register_module(force=True)
@@ -210,9 +210,7 @@ class LSSViewTransformer(BaseModule):
                 (B, N_cams, D, H, W, C).
         """
 
-        ranks_bev, ranks_depth, ranks_feat, \
-            interval_starts, interval_lengths = \
-            self.voxel_pooling_prepare_v2(coor)
+        ranks_bev, ranks_depth, ranks_feat = self.voxel_pooling_prepare_v2(coor)
         # ranks_bev: (N_points, ),
         # ranks_depth: (N_points, ),
         # ranks_feat: (N_points, ),
@@ -222,8 +220,6 @@ class LSSViewTransformer(BaseModule):
         self.ranks_bev = ranks_bev.int().contiguous()
         self.ranks_feat = ranks_feat.int().contiguous()
         self.ranks_depth = ranks_depth.int().contiguous()
-        self.interval_starts = interval_starts.int().contiguous()
-        self.interval_lengths = interval_lengths.int().contiguous()
 
     def voxel_pooling_v2(self, coor, depth, feat):
         """
@@ -234,9 +230,7 @@ class LSSViewTransformer(BaseModule):
         Returns:
             bev_feat: (B, C*Dz(=1), Dy, Dx)
         """
-        ranks_bev, ranks_depth, ranks_feat, \
-            interval_starts, interval_lengths = \
-            self.voxel_pooling_prepare_v2(coor)
+        ranks_bev, ranks_depth, ranks_feat = self.voxel_pooling_prepare_v2(coor)
         # ranks_bev: (N_points, ),
         # ranks_depth: (N_points, ),
         # ranks_feat: (N_points, ),
@@ -258,9 +252,8 @@ class LSSViewTransformer(BaseModule):
         bev_feat_shape = (depth.shape[0], int(self.grid_size[2]),
                           int(self.grid_size[1]), int(self.grid_size[0]),
                           feat.shape[-1])       # (B, Dz, Dy, Dx, C)
-        bev_feat = bev_pool_v2(depth, feat, ranks_depth, ranks_feat, ranks_bev,
-                               bev_feat_shape, interval_starts,
-                               interval_lengths)    # (B, C, Dz, Dy, Dx)
+        bev_feat = bev_pool_v3(depth, feat, ranks_depth, ranks_feat, ranks_bev,
+                               bev_feat_shape)    # (B, C, Dz, Dy, Dx)
         # collapse Z
         if self.collapse_z:
             bev_feat = torch.cat(bev_feat.unbind(dim=2), 1)     # (B, C*Dz, Dy, Dx)
@@ -303,38 +296,36 @@ class LSSViewTransformer(BaseModule):
         coor = torch.cat((coor, batch_idx), 1)      # (B*N*D*fH*fW, 4)   4: (x, y, z, batch_id)
 
         # filter out points that are outside box
-        kept = (coor[:, 0] >= 0) & (coor[:, 0] < self.grid_size[0]) & \
-               (coor[:, 1] >= 0) & (coor[:, 1] < self.grid_size[1]) & \
-               (coor[:, 2] >= 0) & (coor[:, 2] < self.grid_size[2])
+        coor_0, coor_1, coor_2, coor_3 = torch.split(coor, [1, 1, 1, 1], dim=1)
+        grid_size_0, grid_size_1, grid_size_2 = self.grid_size
+        kept = (coor_0 >= 0) & (coor_0 < grid_size_0) & \
+               (coor_1 >= 0) & (coor_1 < grid_size_1) & \
+               (coor_2 >= 0) & (coor_2 < grid_size_2)
         if len(kept) == 0:
-            return None, None, None, None, None
+            return None, None, None
 
         # (N_points, 4), (N_points, ), (N_points, )
-        coor, ranks_depth, ranks_feat = \
-            coor[kept], ranks_depth[kept], ranks_feat[kept]
+        kept_coor_mask = kept.expand_as(coor)
+        coor = torch.masked_select(coor, kept_coor_mask).view(-1, 4)
+        kept = kept.squeeze(-1)
+        ranks_depth = torch.masked_select(ranks_depth, kept)
+        ranks_feat = torch.masked_select(ranks_feat, kept)
 
         # get tensors from the same voxel next to each other
-        ranks_bev = coor[:, 3] * (
-            self.grid_size[2] * self.grid_size[1] * self.grid_size[0])
-        ranks_bev += coor[:, 2] * (self.grid_size[1] * self.grid_size[0])
-        ranks_bev += coor[:, 1] * self.grid_size[0] + coor[:, 0]
-        order = ranks_bev.argsort()
-        # (N_points, ), (N_points, ), (N_points, )
-        ranks_bev, ranks_depth, ranks_feat = \
-            ranks_bev[order], ranks_depth[order], ranks_feat[order]
-
-        kept = torch.ones(
-            ranks_bev.shape[0], device=ranks_bev.device, dtype=torch.bool)
-        kept[1:] = ranks_bev[1:] != ranks_bev[:-1]
-        interval_starts = torch.where(kept)[0].int()
-        if len(interval_starts) == 0:
-            return None, None, None, None, None
-        interval_lengths = torch.zeros_like(interval_starts)
-        interval_lengths[:-1] = interval_starts[1:] - interval_starts[:-1]
-        interval_lengths[-1] = ranks_bev.shape[0] - interval_starts[-1]
+        coor_0, coor_1, coor_2, coor_3 = torch.split(coor, [1, 1, 1, 1], dim=1)
+        coor_0 = coor_0.squeeze(-1)
+        coor_1 = coor_1.squeeze(-1)
+        coor_2 = coor_2.squeeze(-1)
+        coor_3 = coor_3.squeeze(-1)
+        grid_size_0_1 = grid_size_0 * grid_size_1
+
+        ranks_bev = coor_3 * (
+            grid_size_2 * grid_size_0_1)
+        ranks_bev += coor_2 * grid_size_0_1
+        ranks_bev += coor_1 * grid_size_0 + coor_0
+
         return ranks_bev.int().contiguous(), ranks_depth.int().contiguous(
-        ), ranks_feat.int().contiguous(), interval_starts.int().contiguous(
-        ), interval_lengths.int().contiguous()
+        ), ranks_feat.int().contiguous()
 
     def pre_compute(self, input):
         if self.initial_flag:
@@ -369,10 +360,9 @@ class LSSViewTransformer(BaseModule):
             bev_feat_shape = (depth.shape[0], int(self.grid_size[2]),
                               int(self.grid_size[1]), int(self.grid_size[0]),
                               feat.shape[-1])   # (B, Dz, Dy, Dx, C)
-            bev_feat = bev_pool_v2(depth, feat, self.ranks_depth,
+            bev_feat = bev_pool_v3(depth, feat, self.ranks_depth,
                                    self.ranks_feat, self.ranks_bev,
-                                   bev_feat_shape, self.interval_starts,
-                                   self.interval_lengths)   # (B, C, Dz, Dy, Dx)
+                                   bev_feat_shape)   # (B, C, Dz, Dy, Dx)
 
             bev_feat = bev_feat.squeeze(2)      # (B, C, Dy, Dx)
         else:
diff --git a/projects/mmdet3d_plugin/ops/__init__.py b/projects/mmdet3d_plugin/ops/__init__.py
index 53a6016..6009563 100644
--- a/projects/mmdet3d_plugin/ops/__init__.py
+++ b/projects/mmdet3d_plugin/ops/__init__.py
@@ -1,5 +1,4 @@
 from .bev_pool import bev_pool
 from .bev_pool_v2 import bev_pool_v2, TRTBEVPoolv2
-from .nearest_assign import nearest_assign
 
-__all__ = ['bev_pool', 'bev_pool_v2', 'TRTBEVPoolv2', 'nearest_assign']
\ No newline at end of file
+__all__ = ['bev_pool', 'bev_pool_v2', 'TRTBEVPoolv2']
\ No newline at end of file
diff --git a/projects/mmdet3d_plugin/ops/bev_pool/bev_pool.py b/projects/mmdet3d_plugin/ops/bev_pool/bev_pool.py
index 747b213..4747b85 100644
--- a/projects/mmdet3d_plugin/ops/bev_pool/bev_pool.py
+++ b/projects/mmdet3d_plugin/ops/bev_pool/bev_pool.py
@@ -1,126 +1,92 @@
 import torch
 
-from . import bev_pool_ext
+import mx_driving._C
 
 
-class QuickBevPoolingCuda(torch.autograd.Function):
+class BEVPool(torch.autograd.Function):
     @staticmethod
-    def forward(ctx, feats, coords, ranks, B, D, H, W, pooling_method):
-        """
-        Args:
-            ctx:
-            feats: (N, C)
-            coords: (N, 4)   4: (x_id, y_id, z_id, batch_id)
-            ranks:  (N, )  eg: (0, 0, 1, 1, 1, 2, 2)
-            B:
-            D:
-            H:
-            W:
-        Returns:
-            out: (B, D, H, W, C)
-        """
-        kept = torch.ones(feats.shape[0], device=feats.device, dtype=torch.bool)    # (N, )
-        kept[1:] = ranks[1:] != ranks[:-1]      # 边界点=1, 其余为0（pillar id发生变化）    eg:(1, 0, 1, 0, 0, 1, 0)
-        interval_starts = torch.where(kept)[0].int()    # 该pillar的起始位置  (N_pillar, )    eg: (0, 2, 5)
-        interval_lengths = torch.zeros_like(interval_starts)    # pillar包含points的数量  (N_pillar, )  eg: (0, 0, 0)
-        interval_lengths[:-1] = interval_starts[1:] - interval_starts[:-1]   # eg: (0, 2, 5)
-        interval_lengths[-1] = feats.shape[0] - interval_starts[-1]     # eg: (0, 3, 2)
-        coords = coords.int()
+    # pylint: disable=too-many-arguments,huawei-too-many-arguments
+    def forward(ctx, feat, geom_feat, ranks, B, D, H, W):
+        kept = torch.ones(feat.shape[0], device=feat.device, dtype=torch.bool)
+        kept[1:] = ranks[1:] != ranks[:-1]
+        interval_starts = torch.where(kept)[0].int()
+        interval_lengths = torch.zeros_like(interval_starts, dtype=torch.int32)
+        interval_lengths[:-1] = interval_starts[1:] - interval_starts[:-1]
+        interval_lengths[-1] = feat.shape[0] - interval_starts[-1]
+        geom_feat = geom_feat.int()
 
-        if pooling_method == 'sum':
-            out = bev_pool_ext.bev_sum_pool_forward(
-                feats,      # (N, C)
-                coords,     # (N, 4)   4: (x_id, y_id, z_id, batch_id)
-                interval_lengths,   # (N_pillar, )
-                interval_starts,    # (N_pillar, )
-                B,
-                D,
-                H,
-                W,
-            )
-        elif pooling_method == 'max':
-            out = bev_pool_ext.bev_max_pool_forward(
-                feats,      # (N, C)
-                coords,     # (N, 4)   4: (x_id, y_id, z_id, batch_id)
-                interval_lengths,   # (N_pillar, )
-                interval_starts,    # (N_pillar, )
-                B,
-                D,
-                H,
-                W,
-            )
+        out = mx_driving._C.npu_bev_pool(
+            feat,
+            geom_feat,
+            interval_lengths,
+            interval_starts,
+            B,
+            D,
+            H,
+            W,
+        )
 
-        ctx.save_for_backward(interval_starts, interval_lengths, coords)
+        ctx.save_for_backward(interval_starts, interval_lengths, geom_feat)
         ctx.saved_shapes = B, D, H, W
-        ctx.pooling_method = pooling_method
         return out
 
     @staticmethod
-    def backward(ctx, out_grad):
-        """
-        Args:
-            ctx:
-            out_grad: (B, D, H, W, C)
-
-        Returns:
-            x_grad: (N, C)
-        """
-        # (N_pillar, ),  (N_pillar, ),  (N, 4)   4: (x_id, y_id, z_id, batch_id)
-        interval_starts, interval_lengths, geom_coords = ctx.saved_tensors
+    # pylint: disable=too-many-return-values
+    def backward(ctx, grad_out):
+        interval_starts, interval_lengths, geom_feat = ctx.saved_tensors
         B, D, H, W = ctx.saved_shapes
-        pooling_method = ctx.pooling_method
 
-        out_grad = out_grad.contiguous()
-        if pooling_method == 'sum':
-            x_grad = bev_pool_ext.bev_sum_pool_backward(
-                out_grad,               # (B, D, H, W, C)
-                geom_coords,            # (N, 4)   4: (x_id, y_id, z_id, batch_id)
-                interval_lengths,       # (N_pillar, )
-                interval_starts,        # (N_pillar, )
-                B,
-                D,
-                H,
-                W,
-            )   # (N, C)
-        elif pooling_method == 'max':
-            x_grad = bev_pool_ext.bev_max_pool_backward(
-                out_grad,               # (B, D, H, W, C)
-                geom_coords,            # (N, 4)   4: (x_id, y_id, z_id, batch_id)
-                interval_lengths,       # (N_pillar, )
-                interval_starts,        # (N_pillar, )
-                B,
-                D,
-                H,
-                W,
-            )   # (N, C)
+        grad_out = grad_out.contiguous()
+        grad_feat = mx_driving._C.npu_bev_pool_backward(
+            grad_out,
+            geom_feat,
+            interval_lengths,
+            interval_starts,
+            B,
+            D,
+            H,
+            W,
+        )
 
-        return x_grad, None, None, None, None, None, None, None
+        return grad_feat, None, None, None, None, None, None
 
 
-def bev_pool(feats, coords, B, D, H, W, pooling_method='sum'):
+# pylint: disable=too-many-arguments,huawei-too-many-arguments
+def bev_pool(feat, geom_feat, B, D, H, W):
     """
+    bev_pool is a function that pools the features in the BEV (Bird's Eye View) format.
+    Please refer to the paper "BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation"
+    for more details.
     Args:
-        feats: (N, C)
-        coords: (N, 4)  4: (x_id, y_id, z_id, batch_id)
-        B:
-        D:  Dz
-        H:  Dy
-        W:  Dx
+        feat (Tensor): The input feature tensor with shape (N, C).
+        geom_feat (Tensor): The geometry feature tensor with shape (N, 4). The 4 elements are (h, w, d, b).
+        B (int): The number of batch in the BEV.
+        D (int): The number of depth in the BEV.
+        H (int): The height of the BEV.
+        W (int): The width of the BEV.
     Returns:
-        bev_features: (B, C, D, H, W)
+        bev_pooled_feat (Tensor): The pooled feature tensor with shape (B, C, D, H, W).
+    Constraints:
+        - The number of features and geometry features should be the same.
+        - B * D * H * W * C <= 2^31, B, D <= 8, H, W <= 256, C <= 1024, for best practice.
+        - C <= 1024
+    Usage:
+        >>> import torch, torch_npu
+        >>> from mx_driving.perception.fused import bev_pool
+        >>> feat = torch.rand(4, 256).npu()
+        >>> feat.requires_grad_()
+        >>> geom_feat = torch.tensor([[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 2], [0, 0, 0, 3]], dtype=torch.int32).npu()
+        >>> bev_pooled_feat = bev_pool(feat, geom_feat, 4, 1, 256, 256)
+        >>> loss = bev_pooled_feat.sum()
+        >>> loss.backward()
     """
-    assert feats.shape[0] == coords.shape[0]
+    if feat.shape[0] != geom_feat.shape[0]:
+        raise ValueError("The number of features and geometry features should be the same.")
 
-    ranks = (
-        coords[:, 0] * (H * D * B)
-        + coords[:, 1] * (D * B)
-        + coords[:, 2] * B
-        + coords[:, 3]
-    )       # (N, )
-    indices = ranks.argsort()   # (N, )
-    # (N, C), (N, 4), (N, )
-    feats, coords, ranks = feats[indices], coords[indices], ranks[indices]
+    ranks = geom_feat[:, 0] * (W * D * B) + geom_feat[:, 1] * (D * B) + geom_feat[:, 2] * B + geom_feat[:, 3]
+    indices = ranks.argsort()
+    feat, geom_feat, ranks = feat[indices], geom_feat[indices], ranks[indices]
 
-    x = QuickBevPoolingCuda.apply(feats, coords, ranks, B, D, H, W, pooling_method)     # (B, D, H, W, C)
-    x = x.permute(0, 4, 1, 2, 3).contiguous()   # (B, C, D, H, W)
-    return x
+    out = BEVPool.apply(feat, geom_feat, ranks, B, D, H, W)
+    out = out.permute(0, 4, 1, 2, 3).contiguous()
+    return out
diff --git a/projects/mmdet3d_plugin/ops/bev_pool_v2/bev_pool.py b/projects/mmdet3d_plugin/ops/bev_pool_v2/bev_pool.py
index fe9090e..2f755c0 100644
--- a/projects/mmdet3d_plugin/ops/bev_pool_v2/bev_pool.py
+++ b/projects/mmdet3d_plugin/ops/bev_pool_v2/bev_pool.py
@@ -2,8 +2,8 @@
 
 import numpy as np
 import torch
-
-from . import bev_pool_v2_ext
+import mx_driving._C
+from mx_driving import bev_pool_v3
 
 __all__ = ['bev_pool_v2', 'TRTBEVPoolv2']
 
@@ -24,25 +24,19 @@ class QuickCumsumCuda(torch.autograd.Function):
         interval_lengths = interval_lengths.contiguous().int()  # (N_pillar, )
         interval_starts = interval_starts.contiguous().int()    # (N_pillar, )
 
-        out = feat.new_zeros(bev_feat_shape)    # (B, D_Z, D_Y, D_X, C)
-
-        bev_pool_v2_ext.bev_pool_v2_forward(
-            depth,
-            feat,
-            out,
-            ranks_depth,
-            ranks_feat,
-            ranks_bev,
-            interval_lengths,
-            interval_starts,
+        (B, D, H, W, C) = bev_feat_shape
+        out = mx_driving._C.npu_bev_pool_v2(
+            depth, feat, ranks_depth, ranks_feat, ranks_bev, interval_lengths, interval_starts, B, D, H, W
         )
 
         ctx.save_for_backward(ranks_bev, depth, feat, ranks_feat, ranks_depth)
+        ctx.saved_shapes = B, D, H, W
         return out
 
     @staticmethod
     def backward(ctx, out_grad):
         ranks_bev, depth, feat, ranks_feat, ranks_depth = ctx.saved_tensors
+        B, D, H, W = ctx.saved_shapes
 
         order = ranks_feat.argsort()
         ranks_feat, ranks_depth, ranks_bev = \
@@ -64,13 +58,8 @@ class QuickCumsumCuda(torch.autograd.Function):
         interval_lengths_bp = interval_lengths_bp.contiguous()
         interval_starts_bp = interval_starts_bp.contiguous()
 
-        depth_grad = depth.new_zeros(depth.shape)
-        feat_grad = feat.new_zeros(feat.shape)
-        out_grad = out_grad.contiguous()
-        bev_pool_v2_ext.bev_pool_v2_backward(
+        depth_grad, feat_grad = mx_driving._C.npu_bev_pool_v2_backward(
             out_grad,
-            depth_grad,
-            feat_grad,
             depth,
             feat,
             ranks_depth,
@@ -78,6 +67,10 @@ class QuickCumsumCuda(torch.autograd.Function):
             ranks_bev,
             interval_lengths_bp,
             interval_starts_bp,
+            B,
+            D,
+            H,
+            W,
         )
         return depth_grad, feat_grad, None, None, None, None, None, \
             None, None, None
@@ -151,7 +144,7 @@ class TRTBEVPoolv2(torch.autograd.Function):
         depth = depth.unsqueeze(0)
         bev_feat_shape = (depth.shape[0], output_z, output_height, output_width,
                           feat.shape[-1])  # (B, Z, Y, X, C)
-        bev_feat = bev_pool_v2(depth, feat, ranks_depth, ranks_feat, ranks_bev,
+        bev_feat = bev_pool_v3(depth, feat, ranks_depth, ranks_feat, ranks_bev,
                                bev_feat_shape, interval_starts,
                                interval_lengths)
         if output_z == 1:
diff --git a/requirements/runtime.txt b/requirements/runtime.txt
index 643cb0c..ddbec3a 100644
--- a/requirements/runtime.txt
+++ b/requirements/runtime.txt
@@ -1,10 +1,17 @@
+torchvision==0.16.0
+setuptools==59.5.0
+mmsegmentation==0.30.0
 lyft_dataset_sdk
 networkx>=2.2,<2.3
-numba==0.53.0
-numpy
+numba==0.58.1
+numpy==1.23.5
+llvmlite==0.41.1
 nuscenes-devkit
 plyfile
+pyyaml
 scikit-image
 # by default we also use tensorboard to log results
 tensorboard
 trimesh>=2.35.39,<2.35.40
+attrs
+psutil
diff --git a/requirements/tests.txt b/requirements/tests.txt
index 303cc37..23f9d95 100644
--- a/requirements/tests.txt
+++ b/requirements/tests.txt
@@ -10,4 +10,4 @@ pytest-cov
 pytest-runner
 ubelt
 xdoctest >= 0.10.0
-yapf
+yapf==0.40.1
diff --git a/tools/test.py b/tools/test.py
index e5f2063..4f9f7f1 100644
--- a/tools/test.py
+++ b/tools/test.py
@@ -5,9 +5,11 @@ import warnings
 
 import mmcv
 import torch
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 from mmcv import Config, DictAction
 from mmcv.cnn import fuse_conv_bn
-from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
+from mmcv.device.npu import NPUDataParallel, NPUDistributedDataParallel
 from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,
                          wrap_fp16_model)
 
@@ -116,7 +118,7 @@ def parse_args():
         choices=['none', 'pytorch', 'slurm', 'mpi'],
         default='none',
         help='job launcher')
-    parser.add_argument('--local_rank', type=int, default=0)
+    parser.add_argument('--local-rank', type=int, default=0)
     args = parser.parse_args()
     if 'LOCAL_RANK' not in os.environ:
         os.environ['LOCAL_RANK'] = str(args.local_rank)
@@ -256,10 +258,10 @@ def main():
         model.PALETTE = dataset.PALETTE
 
     if not distributed:
-        model = MMDataParallel(model, device_ids=cfg.gpu_ids)
+        model = NPUDataParallel(model, device_ids=cfg.gpu_ids)
         outputs = single_gpu_test(model, data_loader, args.show, args.show_dir)
     else:
-        model = MMDistributedDataParallel(
+        model = NPUDistributedDataParallel(
             model.cuda(),
             device_ids=[torch.cuda.current_device()],
             broadcast_buffers=False)
@@ -287,4 +289,10 @@ def main():
 
 
 if __name__ == '__main__':
-    main()
+    from mx_driving.patcher.patcher import PatcherBuilder, Patch
+    from mx_driving.patcher.tensor import batch_matmul
+    from mx_driving.patcher.mmdet import resnet_add_relu
+
+    pb = PatcherBuilder().add_module_patch("torch", Patch(batch_matmul)).add_module_patch("mmdet.models.backbones.resnet", Patch(resnet_add_relu))
+    with pb.build():
+        main()
diff --git a/tools/train.py b/tools/train.py
index 4c89d46..994cb32 100644
--- a/tools/train.py
+++ b/tools/train.py
@@ -9,6 +9,8 @@ from os import path as osp
 
 import mmcv
 import torch
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 import torch.distributed as dist
 from mmcv import Config, DictAction
 from mmcv.runner import get_dist_info, init_dist
@@ -93,7 +95,7 @@ def parse_args():
         choices=['none', 'pytorch', 'slurm', 'mpi'],
         default='none',
         help='job launcher')
-    parser.add_argument('--local_rank', type=int, default=0)
+    parser.add_argument('--local-rank', type=int, default=0)
     parser.add_argument(
         '--autoscale-lr',
         action='store_true',
@@ -283,4 +285,10 @@ def main():
 
 
 if __name__ == '__main__':
-    main()
+    from mx_driving.patcher.patcher import PatcherBuilder, Patch
+    from mx_driving.patcher.tensor import batch_matmul
+    from mx_driving.patcher.mmdet import resnet_add_relu
+
+    pb = PatcherBuilder().add_module_patch("torch", Patch(batch_matmul)).add_module_patch("mmdet.models.backbones.resnet", Patch(resnet_add_relu))
+    with pb.build():
+        main()
