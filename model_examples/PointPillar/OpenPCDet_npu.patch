diff --git a/.gitignore b/.gitignore
deleted file mode 100644
index 9fd7ec8..0000000
--- a/.gitignore
+++ /dev/null
@@ -1,17 +0,0 @@
-**__pycache__**
-**build**
-**egg-info**
-**dist**
-data/
-*.pyc
-venv/
-*.idea/
-*.so
-*.yaml
-*.sh
-*.pth
-*.pkl
-*.zip
-*.bin
-output
-version.py
diff --git a/2.2_requirements.txt b/2.2_requirements.txt
new file mode 100644
index 0000000..81cb3dd
--- /dev/null
+++ b/2.2_requirements.txt
@@ -0,0 +1,17 @@
+numpy
+llvmlite
+numba
+tensorboardX
+easydict
+pyyaml
+scikit-image
+tqdm
+torchvision==0.17.0
+SharedArray
+opencv-python
+pyquaternion
+pccm==0.3.4
+torch_scatter
+opencv-python-headless
+av2
+kornia==0.6.5
\ No newline at end of file
diff --git a/2.3_requirements.txt b/2.3_requirements.txt
new file mode 100644
index 0000000..75616e0
--- /dev/null
+++ b/2.3_requirements.txt
@@ -0,0 +1,17 @@
+numpy
+llvmlite
+numba
+tensorboardX
+easydict
+pyyaml
+scikit-image
+tqdm
+torchvision==0.18.1
+SharedArray
+opencv-python
+pyquaternion
+pccm==0.3.4
+torch_scatter
+opencv-python-headless
+av2
+kornia==0.6.5
\ No newline at end of file
diff --git a/2.4_requirements.txt b/2.4_requirements.txt
new file mode 100644
index 0000000..1e14305
--- /dev/null
+++ b/2.4_requirements.txt
@@ -0,0 +1,17 @@
+numpy
+llvmlite
+numba
+tensorboardX
+easydict
+pyyaml
+scikit-image
+tqdm
+torchvision==0.19.0
+SharedArray
+opencv-python
+pyquaternion
+pccm==0.3.4
+torch_scatter
+opencv-python-headless
+av2
+kornia==0.6.5
\ No newline at end of file
diff --git a/pcdet/__init__.py b/pcdet/__init__.py
index 9fdf7d2..e69de29 100644
--- a/pcdet/__init__.py
+++ b/pcdet/__init__.py
@@ -1,24 +0,0 @@
-import subprocess
-from pathlib import Path
-
-from .version import __version__
-
-__all__ = [
-    '__version__'
-]
-
-
-def get_git_commit_number():
-    if not (Path(__file__).parent / '../.git').exists():
-        return '0000000'
-
-    cmd_out = subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE)
-    git_commit_number = cmd_out.stdout.decode('utf-8')[:7]
-    return git_commit_number
-
-
-script_version = get_git_commit_number()
-
-
-if script_version not in __version__:
-    __version__ = __version__ + '+py%s' % script_version
diff --git a/pcdet/datasets/kitti/kitti_object_eval_python/eval.py b/pcdet/datasets/kitti/kitti_object_eval_python/eval.py
index 1d2a317..f89f931 100644
--- a/pcdet/datasets/kitti/kitti_object_eval_python/eval.py
+++ b/pcdet/datasets/kitti/kitti_object_eval_python/eval.py
@@ -3,7 +3,8 @@ import io as sysio
 import numba
 import numpy as np
 
-from .rotate_iou import rotate_iou_gpu_eval
+from .rotate_iou import rotate_iou_cpu_eval
+import multiprocessing as mp
 
 
 @numba.jit
@@ -114,7 +115,7 @@ def image_box_overlap(boxes, query_boxes, criterion=-1):
 
 
 def bev_box_overlap(boxes, qboxes, criterion=-1):
-    riou = rotate_iou_gpu_eval(boxes, qboxes, criterion)
+    riou = rotate_iou_cpu_eval(boxes, qboxes, criterion)
     return riou
 
 
@@ -148,7 +149,7 @@ def d3_box_overlap_kernel(boxes, qboxes, rinc, criterion=-1):
 
 
 def d3_box_overlap(boxes, qboxes, criterion=-1):
-    rinc = rotate_iou_gpu_eval(boxes[:, [0, 2, 3, 5, 6]],
+    rinc = rotate_iou_cpu_eval(boxes[:, [0, 2, 3, 5, 6]],
                                qboxes[:, [0, 2, 3, 5, 6]], 2)
     d3_box_overlap_kernel(boxes, qboxes, rinc, criterion)
     return rinc
@@ -337,6 +338,47 @@ def fused_compute_statistics(overlaps,
         dc_num += dc_nums[i]
 
 
+def calculate_iou_partly_single(gt_annos, dt_annos, example_idx, split_parts, i, parted_overlaps, metric):
+    gt_annos_part = gt_annos[example_idx: example_idx + split_parts[i]]
+    dt_annos_part = dt_annos[example_idx: example_idx + split_parts[i]]
+    if metric == 0:
+        gt_boxes = np.concatenate([a["bbox"] for a in gt_annos_part], 0)
+        dt_boxes = np.concatenate([a["bbox"] for a in dt_annos_part], 0)
+        overlap_part = image_box_overlap(gt_boxes, dt_boxes)
+    elif metric == 1:
+        loc = np.concatenate(
+            [a["location"][:, [0, 2]] for a in gt_annos_part], 0)
+        dims = np.concatenate(
+            [a["dimensions"][:, [0, 2]] for a in gt_annos_part], 0)
+        rots = np.concatenate([a["rotation_y"] for a in gt_annos_part], 0)
+        gt_boxes = np.concatenate(
+            [loc, dims, rots[..., np.newaxis]], axis=1)
+        loc = np.concatenate(
+            [a["location"][:, [0, 2]] for a in dt_annos_part], 0)
+        dims = np.concatenate(
+            [a["dimensions"][:, [0, 2]] for a in dt_annos_part], 0)
+        rots = np.concatenate([a["rotation_y"] for a in dt_annos_part], 0)
+        dt_boxes = np.concatenate(
+            [loc, dims, rots[..., np.newaxis]], axis=1)
+        overlap_part = bev_box_overlap(gt_boxes, dt_boxes).astype(
+            np.float64)
+    elif metric == 2:
+        loc = np.concatenate([a["location"] for a in gt_annos_part], 0)
+        dims = np.concatenate([a["dimensions"] for a in gt_annos_part], 0)
+        rots = np.concatenate([a["rotation_y"] for a in gt_annos_part], 0)
+        gt_boxes = np.concatenate([loc, dims, rots[..., np.newaxis]], axis=1)
+        loc = np.concatenate([a["location"] for a in dt_annos_part], 0)
+        dims = np.concatenate([a["dimensions"] for a in dt_annos_part], 0)
+        rots = np.concatenate([a["rotation_y"] for a in dt_annos_part], 0)
+        dt_boxes = np.concatenate(
+            [loc, dims, rots[..., np.newaxis]], axis=1)
+        overlap_part = d3_box_overlap(gt_boxes, dt_boxes).astype(
+            np.float64)
+    else:
+        raise ValueError("unknown metric")
+    
+    parted_overlaps[i] = overlap_part
+
 def calculate_iou_partly(gt_annos, dt_annos, metric, num_parts=50):
     """fast iou algorithm. this function can be used independently to
     do result analysis. Must be used in CAMERA coordinate system.
@@ -354,47 +396,18 @@ def calculate_iou_partly(gt_annos, dt_annos, metric, num_parts=50):
     parted_overlaps = []
     example_idx = 0
 
-    for num_part in split_parts:
-        gt_annos_part = gt_annos[example_idx:example_idx + num_part]
-        dt_annos_part = dt_annos[example_idx:example_idx + num_part]
-        if metric == 0:
-            gt_boxes = np.concatenate([a["bbox"] for a in gt_annos_part], 0)
-            dt_boxes = np.concatenate([a["bbox"] for a in dt_annos_part], 0)
-            overlap_part = image_box_overlap(gt_boxes, dt_boxes)
-        elif metric == 1:
-            loc = np.concatenate(
-                [a["location"][:, [0, 2]] for a in gt_annos_part], 0)
-            dims = np.concatenate(
-                [a["dimensions"][:, [0, 2]] for a in gt_annos_part], 0)
-            rots = np.concatenate([a["rotation_y"] for a in gt_annos_part], 0)
-            gt_boxes = np.concatenate(
-                [loc, dims, rots[..., np.newaxis]], axis=1)
-            loc = np.concatenate(
-                [a["location"][:, [0, 2]] for a in dt_annos_part], 0)
-            dims = np.concatenate(
-                [a["dimensions"][:, [0, 2]] for a in dt_annos_part], 0)
-            rots = np.concatenate([a["rotation_y"] for a in dt_annos_part], 0)
-            dt_boxes = np.concatenate(
-                [loc, dims, rots[..., np.newaxis]], axis=1)
-            overlap_part = bev_box_overlap(gt_boxes, dt_boxes).astype(
-                np.float64)
-        elif metric == 2:
-            loc = np.concatenate([a["location"] for a in gt_annos_part], 0)
-            dims = np.concatenate([a["dimensions"] for a in gt_annos_part], 0)
-            rots = np.concatenate([a["rotation_y"] for a in gt_annos_part], 0)
-            gt_boxes = np.concatenate(
-                [loc, dims, rots[..., np.newaxis]], axis=1)
-            loc = np.concatenate([a["location"] for a in dt_annos_part], 0)
-            dims = np.concatenate([a["dimensions"] for a in dt_annos_part], 0)
-            rots = np.concatenate([a["rotation_y"] for a in dt_annos_part], 0)
-            dt_boxes = np.concatenate(
-                [loc, dims, rots[..., np.newaxis]], axis=1)
-            overlap_part = d3_box_overlap(gt_boxes, dt_boxes).astype(
-                np.float64)
-        else:
-            raise ValueError("unknown metric")
-        parted_overlaps.append(overlap_part)
-        example_idx += num_part
+    parted_overlaps = mp.Manager().list([None] * len(split_parts))
+    num_processes = len(split_parts)
+    processes = []
+    for i in range(num_processes):
+        p = mp.Process(target=calculate_iou_partly_single, args=(gt_annos, dt_annos, example_idx, split_parts, i, parted_overlaps, metric))
+        example_idx += split_parts[i]
+        processes.append(p)
+        p.start()
+    for p in processes:
+        p.join()
+        
+    parted_overlaps = list(parted_overlaps)
     overlaps = []
     example_idx = 0
     for j, num_part in enumerate(split_parts):
diff --git a/pcdet/datasets/kitti/kitti_object_eval_python/rotate_iou.py b/pcdet/datasets/kitti/kitti_object_eval_python/rotate_iou.py
index 543d8f2..3cce4c2 100644
--- a/pcdet/datasets/kitti/kitti_object_eval_python/rotate_iou.py
+++ b/pcdet/datasets/kitti/kitti_object_eval_python/rotate_iou.py
@@ -10,17 +10,15 @@ import numpy as np
 from numba import cuda
 
 
-@numba.jit(nopython=True)
 def div_up(m, n):
     return m // n + (m % n > 0)
 
-@cuda.jit('(float32[:], float32[:], float32[:])', device=True, inline=True)
+
 def trangle_area(a, b, c):
     return ((a[0] - c[0]) * (b[1] - c[1]) - (a[1] - c[1]) *
             (b[0] - c[0])) / 2.0
 
 
-@cuda.jit('(float32[:], int32)', device=True, inline=True)
 def area(int_pts, num_of_inter):
     area_val = 0.0
     for i in range(num_of_inter - 2):
@@ -30,18 +28,17 @@ def area(int_pts, num_of_inter):
     return area_val
 
 
-@cuda.jit('(float32[:], int32)', device=True, inline=True)
 def sort_vertex_in_convex_polygon(int_pts, num_of_inter):
     if num_of_inter > 0:
-        center = cuda.local.array((2, ), dtype=numba.float32)
+        center = np.zeros((2, ), dtype=np.float32)
         center[:] = 0.0
         for i in range(num_of_inter):
             center[0] += int_pts[2 * i]
             center[1] += int_pts[2 * i + 1]
         center[0] /= num_of_inter
         center[1] /= num_of_inter
-        v = cuda.local.array((2, ), dtype=numba.float32)
-        vs = cuda.local.array((16, ), dtype=numba.float32)
+        v = np.zeros((2, ), dtype=np.float32)
+        vs = np.zeros((16, ), dtype=np.float32)
         for i in range(num_of_inter):
             v[0] = int_pts[2 * i] - center[0]
             v[1] = int_pts[2 * i + 1] - center[1]
@@ -70,15 +67,11 @@ def sort_vertex_in_convex_polygon(int_pts, num_of_inter):
                 int_pts[j * 2 + 1] = ty
 
 
-@cuda.jit(
-    '(float32[:], float32[:], int32, int32, float32[:])',
-    device=True,
-    inline=True)
 def line_segment_intersection(pts1, pts2, i, j, temp_pts):
-    A = cuda.local.array((2, ), dtype=numba.float32)
-    B = cuda.local.array((2, ), dtype=numba.float32)
-    C = cuda.local.array((2, ), dtype=numba.float32)
-    D = cuda.local.array((2, ), dtype=numba.float32)
+    A = np.zeros((2, ), dtype=np.float32)
+    B = np.zeros((2, ), dtype=np.float32)
+    C = np.zeros((2, ), dtype=np.float32)
+    D = np.zeros((2, ), dtype=np.float32)
 
     A[0] = pts1[2 * i]
     A[1] = pts1[2 * i + 1]
@@ -116,15 +109,11 @@ def line_segment_intersection(pts1, pts2, i, j, temp_pts):
     return False
 
 
-@cuda.jit(
-    '(float32[:], float32[:], int32, int32, float32[:])',
-    device=True,
-    inline=True)
 def line_segment_intersection_v1(pts1, pts2, i, j, temp_pts):
-    a = cuda.local.array((2, ), dtype=numba.float32)
-    b = cuda.local.array((2, ), dtype=numba.float32)
-    c = cuda.local.array((2, ), dtype=numba.float32)
-    d = cuda.local.array((2, ), dtype=numba.float32)
+    a = np.zeros((2, ), dtype=np.float32)
+    b = np.zeros((2, ), dtype=np.float32)
+    c = np.zeros((2, ), dtype=np.float32)
+    d = np.zeros((2, ), dtype=np.float32)
 
     a[0] = pts1[2 * i]
     a[1] = pts1[2 * i + 1]
@@ -158,7 +147,6 @@ def line_segment_intersection_v1(pts1, pts2, i, j, temp_pts):
     return True
 
 
-@cuda.jit('(float32, float32, float32[:])', device=True, inline=True)
 def point_in_quadrilateral(pt_x, pt_y, corners):
     ab0 = corners[2] - corners[0]
     ab1 = corners[3] - corners[1]
@@ -177,7 +165,6 @@ def point_in_quadrilateral(pt_x, pt_y, corners):
     return abab >= abap and abap >= 0 and adad >= adap and adap >= 0
 
 
-@cuda.jit('(float32[:], float32[:], float32[:])', device=True, inline=True)
 def quadrilateral_intersection(pts1, pts2, int_pts):
     num_of_inter = 0
     for i in range(4):
@@ -189,7 +176,7 @@ def quadrilateral_intersection(pts1, pts2, int_pts):
             int_pts[num_of_inter * 2] = pts2[2 * i]
             int_pts[num_of_inter * 2 + 1] = pts2[2 * i + 1]
             num_of_inter += 1
-    temp_pts = cuda.local.array((2, ), dtype=numba.float32)
+    temp_pts = np.zeros((2, ), dtype=np.float32)
     for i in range(4):
         for j in range(4):
             has_pts = line_segment_intersection(pts1, pts2, i, j, temp_pts)
@@ -201,7 +188,6 @@ def quadrilateral_intersection(pts1, pts2, int_pts):
     return num_of_inter
 
 
-@cuda.jit('(float32[:], float32[:])', device=True, inline=True)
 def rbbox_to_corners(corners, rbbox):
     # generate clockwise corners and rotate it clockwise
     angle = rbbox[4]
@@ -211,8 +197,8 @@ def rbbox_to_corners(corners, rbbox):
     center_y = rbbox[1]
     x_d = rbbox[2]
     y_d = rbbox[3]
-    corners_x = cuda.local.array((4, ), dtype=numba.float32)
-    corners_y = cuda.local.array((4, ), dtype=numba.float32)
+    corners_x = np.zeros((4, ), dtype=np.float32)
+    corners_y = np.zeros((4, ), dtype=np.float32)
     corners_x[0] = -x_d / 2
     corners_x[1] = -x_d / 2
     corners_x[2] = x_d / 2
@@ -228,11 +214,10 @@ def rbbox_to_corners(corners, rbbox):
                 + 1] = -a_sin * corners_x[i] + a_cos * corners_y[i] + center_y
 
 
-@cuda.jit('(float32[:], float32[:])', device=True, inline=True)
 def inter(rbbox1, rbbox2):
-    corners1 = cuda.local.array((8, ), dtype=numba.float32)
-    corners2 = cuda.local.array((8, ), dtype=numba.float32)
-    intersection_corners = cuda.local.array((16, ), dtype=numba.float32)
+    corners1 = np.zeros((8, ), dtype=np.float32)
+    corners2 = np.zeros((8, ), dtype=np.float32)
+    intersection_corners = np.zeros((16, ), dtype=np.float32)
 
     rbbox_to_corners(corners1, rbbox1)
     rbbox_to_corners(corners2, rbbox2)
@@ -245,7 +230,6 @@ def inter(rbbox1, rbbox2):
     return area(intersection_corners, num_intersection)
 
 
-@cuda.jit('(float32[:], float32[:], int32)', device=True, inline=True)
 def devRotateIoUEval(rbox1, rbox2, criterion=-1):
     area1 = rbox1[2] * rbox1[3]
     area2 = rbox2[2] * rbox2[3]
@@ -259,7 +243,7 @@ def devRotateIoUEval(rbox1, rbox2, criterion=-1):
     else:
         return area_inter
 
-@cuda.jit('(int64, int64, float32[:], float32[:], float32[:], int32)', fastmath=False)
+
 def rotate_iou_kernel_eval(N, K, dev_boxes, dev_query_boxes, dev_iou, criterion=-1):
     threadsPerBlock = 8 * 8
     row_start = cuda.blockIdx.x
@@ -328,3 +312,15 @@ def rotate_iou_gpu_eval(boxes, query_boxes, criterion=-1, device_id=0):
             N, K, boxes_dev, query_boxes_dev, iou_dev, criterion)
         iou_dev.copy_to_host(iou.reshape([-1]), stream=stream)
     return iou.astype(boxes.dtype)
+
+
+def rotate_iou_cpu_eval(dev_boxes, dev_query_boxes, criterion=-1):
+    num_boxes = dev_boxes.shape[0]
+    num_qboxes = dev_query_boxes.shape[0]
+    dev_iou = np.zeros((num_boxes, num_qboxes))
+    
+    for box_i in range(num_boxes):
+        for qbox_i in range(num_qboxes):
+            dev_iou[box_i, qbox_i] = devRotateIoUEval(dev_query_boxes[qbox_i], dev_boxes[box_i], criterion)
+    
+    return dev_iou
\ No newline at end of file
diff --git a/pcdet/datasets/nuscenes/nuscenes_dataset.py b/pcdet/datasets/nuscenes/nuscenes_dataset.py
index 0f70005..19ccf95 100644
--- a/pcdet/datasets/nuscenes/nuscenes_dataset.py
+++ b/pcdet/datasets/nuscenes/nuscenes_dataset.py
@@ -1,3 +1,5 @@
+# Copyright 2024 Huawei Technologies Co., Ltd
+
 import copy
 import pickle
 from pathlib import Path
@@ -11,6 +13,10 @@ from ..dataset import DatasetTemplate
 from pyquaternion import Quaternion
 from PIL import Image
 
+import torch
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
+
 
 class NuScenesDataset(DatasetTemplate):
     def __init__(self, dataset_cfg, class_names, training=True, root_path=None, logger=None):
diff --git a/pcdet/models/backbones_2d/map_to_bev/pointpillar_scatter.py b/pcdet/models/backbones_2d/map_to_bev/pointpillar_scatter.py
index c57cda8..ceb5779 100644
--- a/pcdet/models/backbones_2d/map_to_bev/pointpillar_scatter.py
+++ b/pcdet/models/backbones_2d/map_to_bev/pointpillar_scatter.py
@@ -9,22 +9,28 @@ class PointPillarScatter(nn.Module):
         self.model_cfg = model_cfg
         self.num_bev_features = self.model_cfg.NUM_BEV_FEATURES
         self.nx, self.ny, self.nz = grid_size
+        self.nums = self.nz * self.nx * self.ny
         assert self.nz == 1
 
     def forward(self, batch_dict, **kwargs):
         pillar_features, coords = batch_dict['pillar_features'], batch_dict['voxel_coords']
+        coords_dim1_length = coords.shape[1]
+        coords_0, coords_1, coords_2, coords_3, _ = torch.split(coords, [1, 1, 1, 1, coords_dim1_length-4], dim=1)
+        coords_0 = coords_0.squeeze(1)
+        coords_1 = coords_1.squeeze(1)
+        coords_2 = coords_2.squeeze(1)
+        coords_3 = coords_3.squeeze(1)
         batch_spatial_features = []
-        batch_size = coords[:, 0].max().int().item() + 1
+        batch_size = coords_0.max().int().item() + 1
         for batch_idx in range(batch_size):
             spatial_feature = torch.zeros(
                 self.num_bev_features,
-                self.nz * self.nx * self.ny,
+                self.nums,
                 dtype=pillar_features.dtype,
                 device=pillar_features.device)
 
-            batch_mask = coords[:, 0] == batch_idx
-            this_coords = coords[batch_mask, :]
-            indices = this_coords[:, 1] + this_coords[:, 2] * self.nx + this_coords[:, 3]
+            batch_mask = coords_0 == batch_idx
+            indices = coords_1[batch_mask] + coords_2[batch_mask] * self.nx + coords_3[batch_mask]
             indices = indices.type(torch.long)
             pillars = pillar_features[batch_mask, :]
             pillars = pillars.t()
diff --git a/pcdet/models/backbones_3d/__init__.py b/pcdet/models/backbones_3d/__init__.py
index 0a25c62..78c4998 100644
--- a/pcdet/models/backbones_3d/__init__.py
+++ b/pcdet/models/backbones_3d/__init__.py
@@ -1,22 +1,22 @@
-from .pointnet2_backbone import PointNet2Backbone, PointNet2MSG
+# from .pointnet2_backbone import PointNet2Backbone, PointNet2MSG
 from .spconv_backbone import VoxelBackBone8x, VoxelResBackBone8x
-from .spconv_backbone_2d import PillarBackBone8x, PillarRes18BackBone8x
-from .spconv_backbone_focal import VoxelBackBone8xFocal
-from .spconv_backbone_voxelnext import VoxelResBackBone8xVoxelNeXt
-from .spconv_backbone_voxelnext2d import VoxelResBackBone8xVoxelNeXt2D
-from .spconv_unet import UNetV2
-from .dsvt import DSVT
+# from .spconv_backbone_2d import PillarBackBone8x, PillarRes18BackBone8x
+# from .spconv_backbone_focal import VoxelBackBone8xFocal
+# from .spconv_backbone_voxelnext import VoxelResBackBone8xVoxelNeXt
+# from .spconv_backbone_voxelnext2d import VoxelResBackBone8xVoxelNeXt2D
+# from .spconv_unet import UNetV2
+# from .dsvt import DSVT
 
 __all__ = {
     'VoxelBackBone8x': VoxelBackBone8x,
-    'UNetV2': UNetV2,
-    'PointNet2Backbone': PointNet2Backbone,
-    'PointNet2MSG': PointNet2MSG,
+#     'UNetV2': UNetV2,
+#     'PointNet2Backbone': PointNet2Backbone,
+#     'PointNet2MSG': PointNet2MSG,
     'VoxelResBackBone8x': VoxelResBackBone8x,
-    'VoxelBackBone8xFocal': VoxelBackBone8xFocal,
-    'VoxelResBackBone8xVoxelNeXt': VoxelResBackBone8xVoxelNeXt,
-    'VoxelResBackBone8xVoxelNeXt2D': VoxelResBackBone8xVoxelNeXt2D,
-    'PillarBackBone8x': PillarBackBone8x,
-    'PillarRes18BackBone8x': PillarRes18BackBone8x,
-    'DSVT': DSVT,
+#     'VoxelBackBone8xFocal': VoxelBackBone8xFocal,
+#     'VoxelResBackBone8xVoxelNeXt': VoxelResBackBone8xVoxelNeXt,
+#     'VoxelResBackBone8xVoxelNeXt2D': VoxelResBackBone8xVoxelNeXt2D,
+#     'PillarBackBone8x': PillarBackBone8x,
+#     'PillarRes18BackBone8x': PillarRes18BackBone8x,
+#     'DSVT': DSVT,
 }
diff --git a/pcdet/models/backbones_3d/spconv_backbone.py b/pcdet/models/backbones_3d/spconv_backbone.py
index f0c231a..ef0cc18 100644
--- a/pcdet/models/backbones_3d/spconv_backbone.py
+++ b/pcdet/models/backbones_3d/spconv_backbone.py
@@ -2,19 +2,20 @@ from functools import partial
 
 import torch.nn as nn
 
-from ...utils.spconv_utils import replace_feature, spconv
+from ...utils.spconv_utils import replace_feature
+from mx_driving import spconv
 
 
 def post_act_block(in_channels, out_channels, kernel_size, indice_key=None, stride=1, padding=0,
                    conv_type='subm', norm_fn=None):
 
     if conv_type == 'subm':
-        conv = spconv.SubMConv3d(in_channels, out_channels, kernel_size, bias=False, indice_key=indice_key)
+        conv = spconv.SubMConv3d(in_channels, out_channels, kernel_size, bias=False, mode='spconv', indice_key=indice_key)
     elif conv_type == 'spconv':
         conv = spconv.SparseConv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding,
-                                   bias=False, indice_key=indice_key)
+                                   bias=False, mode='spconv', indice_key=indice_key)
     elif conv_type == 'inverseconv':
-        conv = spconv.SparseInverseConv3d(in_channels, out_channels, kernel_size, indice_key=indice_key, bias=False)
+        conv = spconv.SparseInverseConv3d(in_channels, out_channels, kernel_size, mode='spconv', indice_key=indice_key, bias=False)
     else:
         raise NotImplementedError
 
@@ -37,12 +38,12 @@ class SparseBasicBlock(spconv.SparseModule):
         if bias is None:
             bias = norm_fn is not None
         self.conv1 = spconv.SubMConv3d(
-            inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=bias, indice_key=indice_key
+            inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=bias, mode='spconv', indice_key=indice_key
         )
         self.bn1 = norm_fn(planes)
         self.relu = nn.ReLU()
         self.conv2 = spconv.SubMConv3d(
-            planes, planes, kernel_size=3, stride=stride, padding=1, bias=bias, indice_key=indice_key
+            planes, planes, kernel_size=3, stride=stride, padding=1, bias=bias, mode='spconv', indice_key=indice_key
         )
         self.bn2 = norm_fn(planes)
         self.downsample = downsample
@@ -76,7 +77,7 @@ class VoxelBackBone8x(nn.Module):
         self.sparse_shape = grid_size[::-1] + [1, 0, 0]
 
         self.conv_input = spconv.SparseSequential(
-            spconv.SubMConv3d(input_channels, 16, 3, padding=1, bias=False, indice_key='subm1'),
+            spconv.SubMConv3d(input_channels, 16, 3, padding=1, bias=False, mode='spconv', indice_key='subm1'),
             norm_fn(16),
             nn.ReLU(),
         )
@@ -112,7 +113,7 @@ class VoxelBackBone8x(nn.Module):
         self.conv_out = spconv.SparseSequential(
             # [200, 150, 5] -> [200, 150, 2]
             spconv.SparseConv3d(64, 128, (3, 1, 1), stride=(2, 1, 1), padding=last_pad,
-                                bias=False, indice_key='spconv_down2'),
+                                bias=False, mode='spconv', indice_key='spconv_down2'),
             norm_fn(128),
             nn.ReLU(),
         )
@@ -191,7 +192,7 @@ class VoxelResBackBone8x(nn.Module):
         self.sparse_shape = grid_size[::-1] + [1, 0, 0]
 
         self.conv_input = spconv.SparseSequential(
-            spconv.SubMConv3d(input_channels, 16, 3, padding=1, bias=False, indice_key='subm1'),
+            spconv.SubMConv3d(input_channels, 16, 3, padding=1, bias=False, mode='spconv', indice_key='subm1'),
             norm_fn(16),
             nn.ReLU(),
         )
@@ -228,7 +229,7 @@ class VoxelResBackBone8x(nn.Module):
         self.conv_out = spconv.SparseSequential(
             # [200, 150, 5] -> [200, 150, 2]
             spconv.SparseConv3d(128, 128, (3, 1, 1), stride=(2, 1, 1), padding=last_pad,
-                                bias=False, indice_key='spconv_down2'),
+                                bias=False, mode='spconv', indice_key='spconv_down2'),
             norm_fn(128),
             nn.ReLU(),
         )
@@ -291,5 +292,5 @@ class VoxelResBackBone8x(nn.Module):
                 'x_conv4': 8,
             }
         })
-        
+
         return batch_dict
diff --git a/pcdet/models/backbones_3d/vfe/dynamic_pillar_vfe.py b/pcdet/models/backbones_3d/vfe/dynamic_pillar_vfe.py
index f5fb6b1..d9876cb 100644
--- a/pcdet/models/backbones_3d/vfe/dynamic_pillar_vfe.py
+++ b/pcdet/models/backbones_3d/vfe/dynamic_pillar_vfe.py
@@ -1,3 +1,5 @@
+# Copyright 2024 Huawei Technologies Co., Ltd
+
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
@@ -99,8 +101,11 @@ class DynamicPillarVFE(VFETemplate):
         merge_coords = points[:, 0].int() * self.scale_xy + \
                        points_coords[:, 0] * self.scale_y + \
                        points_coords[:, 1]
-        
-        unq_coords, unq_inv, unq_cnt = torch.unique(merge_coords, return_inverse=True, return_counts=True, dim=0)
+
+        import numpy as np
+        unq_coords, unq_inv = np.unique(merge_coords.cpu().numpy(), return_inverse=True)
+        unq_coords = torch.from_numpy(unq_coords).npu()
+        unq_inv = torch.from_numpy(unq_inv).npu()
 
         points_mean = torch_scatter.scatter_mean(points_xyz, unq_inv, dim=0)
         f_cluster = points_xyz - points_mean[unq_inv, :]
diff --git a/pcdet/models/backbones_3d/vfe/pillar_vfe.py b/pcdet/models/backbones_3d/vfe/pillar_vfe.py
index a162a83..c84215f 100644
--- a/pcdet/models/backbones_3d/vfe/pillar_vfe.py
+++ b/pcdet/models/backbones_3d/vfe/pillar_vfe.py
@@ -39,7 +39,7 @@ class PFNLayer(nn.Module):
         x = self.norm(x.permute(0, 2, 1)).permute(0, 2, 1) if self.use_norm else x
         torch.backends.cudnn.enabled = True
         x = F.relu(x)
-        x_max = torch.max(x, dim=1, keepdim=True)[0]
+        x_max = torch.max(x.transpose(0,1), dim=0)[0].unsqueeze(0).transpose(0,1)
 
         if self.last_vfe:
             return x_max
@@ -94,13 +94,18 @@ class PillarVFE(VFETemplate):
     def forward(self, batch_dict, **kwargs):
   
         voxel_features, voxel_num_points, coords = batch_dict['voxels'], batch_dict['voxel_num_points'], batch_dict['voxel_coords']
-        points_mean = voxel_features[:, :, :3].sum(dim=1, keepdim=True) / voxel_num_points.type_as(voxel_features).view(-1, 1, 1)
-        f_cluster = voxel_features[:, :, :3] - points_mean
-
-        f_center = torch.zeros_like(voxel_features[:, :, :3])
-        f_center[:, :, 0] = voxel_features[:, :, 0] - (coords[:, 3].to(voxel_features.dtype).unsqueeze(1) * self.voxel_x + self.x_offset)
-        f_center[:, :, 1] = voxel_features[:, :, 1] - (coords[:, 2].to(voxel_features.dtype).unsqueeze(1) * self.voxel_y + self.y_offset)
-        f_center[:, :, 2] = voxel_features[:, :, 2] - (coords[:, 1].to(voxel_features.dtype).unsqueeze(1) * self.voxel_z + self.z_offset)
+        voxel_features_3 = voxel_features[:, :, :3]
+        voxel_features_dim2_length = voxel_features.shape[2]
+        voxel_features_0, voxel_features_1, voxel_features_2, _ = torch.split(voxel_features, [1, 1, 1, voxel_features_dim2_length-3], dim=2)
+        coords_dim1_length = coords.shape[1]
+        coords_0, coords_1, coords_2, coords_3, _ = torch.split(coords, [1, 1, 1, 1, coords_dim1_length-4], dim=1)
+        points_mean = voxel_features_3.sum(dim=1, keepdim=True) / voxel_num_points.type_as(voxel_features).view(-1, 1, 1)
+        f_cluster = voxel_features_3 - points_mean
+
+        f_center = torch.zeros_like(voxel_features_3)
+        f_center[:, :, 0] = voxel_features_0.squeeze(2) - (coords_3.to(voxel_features.dtype) * self.voxel_x + self.x_offset)
+        f_center[:, :, 1] = voxel_features_1.squeeze(2) - (coords_2.to(voxel_features.dtype) * self.voxel_y + self.y_offset)
+        f_center[:, :, 2] = voxel_features_2.squeeze(2) - (coords_1.to(voxel_features.dtype) * self.voxel_z + self.z_offset)
 
         if self.use_absolute_xyz:
             features = [voxel_features, f_cluster, f_center]
@@ -108,7 +113,7 @@ class PillarVFE(VFETemplate):
             features = [voxel_features[..., 3:], f_cluster, f_center]
 
         if self.with_distance:
-            points_dist = torch.norm(voxel_features[:, :, :3], 2, 2, keepdim=True)
+            points_dist = torch.norm(voxel_features_3, 2, 2, keepdim=True)
             features.append(points_dist)
         features = torch.cat(features, dim=-1)
 
diff --git a/pcdet/models/dense_heads/target_assigner/anchor_generator.py b/pcdet/models/dense_heads/target_assigner/anchor_generator.py
index 0aa6861..d980478 100644
--- a/pcdet/models/dense_heads/target_assigner/anchor_generator.py
+++ b/pcdet/models/dense_heads/target_assigner/anchor_generator.py
@@ -74,6 +74,4 @@ if __name__ == '__main__':
         anchor_range=[-75.2, -75.2, -2, 75.2, 75.2, 4],
         anchor_generator_config=config
     )
-    import pdb
-    pdb.set_trace()
     A.generate_anchors([[188, 188]])
diff --git a/pcdet/models/detectors/detector3d_template.py b/pcdet/models/detectors/detector3d_template.py
index 91e44bd..d0e83eb 100644
--- a/pcdet/models/detectors/detector3d_template.py
+++ b/pcdet/models/detectors/detector3d_template.py
@@ -305,7 +305,7 @@ class Detector3DTemplate(nn.Module):
 
         if cur_gt.shape[0] > 0:
             if box_preds.shape[0] > 0:
-                iou3d_rcnn = iou3d_nms_utils.boxes_iou3d_gpu(box_preds[:, 0:7], cur_gt[:, 0:7])
+                iou3d_rcnn = iou3d_nms_utils.boxes_bev_iou_cpu(box_preds[:, 0:7].cpu(), cur_gt[:, 0:7].cpu()).npu()
             else:
                 iou3d_rcnn = torch.zeros((0, cur_gt.shape[0]))
 
diff --git a/pcdet/ops/bev_pool/bev_pool.py b/pcdet/ops/bev_pool/bev_pool.py
index 5769a40..9eb7a71 100644
--- a/pcdet/ops/bev_pool/bev_pool.py
+++ b/pcdet/ops/bev_pool/bev_pool.py
@@ -1,6 +1,5 @@
 import torch
 
-from . import bev_pool_ext
 
 __all__ = ["bev_pool"]
 
diff --git a/pcdet/ops/iou3d_nms/iou3d_nms_utils.py b/pcdet/ops/iou3d_nms/iou3d_nms_utils.py
index b63ca0d..641e329 100644
--- a/pcdet/ops/iou3d_nms/iou3d_nms_utils.py
+++ b/pcdet/ops/iou3d_nms/iou3d_nms_utils.py
@@ -131,7 +131,7 @@ def nms_gpu(boxes, scores, thresh, pre_maxsize=None, **kwargs):
 
     boxes = boxes[order].contiguous()
     keep = torch.LongTensor(boxes.size(0))
-    num_out = iou3d_nms_cuda.nms_gpu(boxes, keep, thresh)
+    num_out = iou3d_nms_cuda.nms_cpu(boxes.cpu(), keep.cpu(), thresh)
     return order[keep[:num_out].cuda()].contiguous(), None
 
 
@@ -148,7 +148,7 @@ def nms_normal_gpu(boxes, scores, thresh, **kwargs):
     boxes = boxes[order].contiguous()
 
     keep = torch.LongTensor(boxes.size(0))
-    num_out = iou3d_nms_cuda.nms_normal_gpu(boxes, keep, thresh)
+    num_out = iou3d_nms_cuda.nms_cpu(boxes, keep, thresh)
     return order[keep[:num_out].cuda()].contiguous(), None
 
 
diff --git a/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp b/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp
index c0311b3..a3e13dd 100644
--- a/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp
+++ b/pcdet/ops/iou3d_nms/src/iou3d_cpu.cpp
@@ -9,23 +9,8 @@ All Rights Reserved 2020.
 #include <torch/serialize/tensor.h>
 #include <torch/extension.h>
 #include <vector>
-#include <cuda.h>
-#include <cuda_runtime_api.h>
 #include "iou3d_cpu.h"
 
-#define CHECK_CUDA(x) do { \
-  if (!x.type().is_cuda()) { \
-    fprintf(stderr, "%s must be CUDA tensor at %s:%d\n", #x, __FILE__, __LINE__); \
-    exit(-1); \
-  } \
-} while (0)
-#define CHECK_CONTIGUOUS(x) do { \
-  if (!x.is_contiguous()) { \
-    fprintf(stderr, "%s must be contiguous tensor at %s:%d\n", #x, __FILE__, __LINE__); \
-    exit(-1); \
-  } \
-} while (0)
-#define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
 
 inline float min(float a, float b){
     return a > b ? b : a;
@@ -38,20 +23,20 @@ inline float max(float a, float b){
 const float EPS = 1e-8;
 struct Point {
     float x, y;
-    __device__ Point() {}
-    __device__ Point(double _x, double _y){
+    Point() {}
+    Point(double _x, double _y){
         x = _x, y = _y;
     }
 
-    __device__ void set(float _x, float _y){
+    void set(float _x, float _y){
         x = _x; y = _y;
     }
 
-    __device__ Point operator +(const Point &b)const{
+    Point operator +(const Point &b)const{
         return Point(x + b.x, y + b.y);
     }
 
-    __device__ Point operator -(const Point &b)const{
+    Point operator -(const Point &b)const{
         return Point(x - b.x, y - b.y);
     }
 };
@@ -234,9 +219,6 @@ int boxes_iou_bev_cpu(at::Tensor boxes_a_tensor, at::Tensor boxes_b_tensor, at::
     // params boxes_b_tensor: (M, 7) [x, y, z, dx, dy, dz, heading]
     // params ans_iou_tensor: (N, M)
 
-    CHECK_CONTIGUOUS(boxes_a_tensor);
-    CHECK_CONTIGUOUS(boxes_b_tensor);
-
     int num_boxes_a = boxes_a_tensor.size(0);
     int num_boxes_b = boxes_b_tensor.size(0);
     const float *boxes_a = boxes_a_tensor.data<float>();
@@ -256,9 +238,6 @@ int boxes_aligned_iou_bev_cpu(at::Tensor boxes_a_tensor, at::Tensor boxes_b_tens
     // params boxes_b_tensor: (N, 7) [x, y, z, dx, dy, dz, heading]
     // params ans_iou_tensor: (N, 1)
 
-    CHECK_CONTIGUOUS(boxes_a_tensor);
-    CHECK_CONTIGUOUS(boxes_b_tensor);
-
     int num_boxes = boxes_a_tensor.size(0);
     int num_boxes_b = boxes_b_tensor.size(0);
     assert(num_boxes == num_boxes_b);
@@ -271,3 +250,33 @@ int boxes_aligned_iou_bev_cpu(at::Tensor boxes_a_tensor, at::Tensor boxes_b_tens
     }
     return 1;
 }
+
+int nms_cpu(at::Tensor boxes, at::Tensor keep, float nms_overlap_thresh) {
+    int boxes_num = boxes.size(0);
+    const float * boxes_data = boxes.data<float>();
+    long * keep_data = keep.data<long>();
+
+    int num_to_keep = 0;
+
+    std::vector<int> boxIndex;
+    for (int i = 0; i < boxes_num; i++) {
+        boxIndex.push_back(i);
+    }
+
+    while (boxIndex.size() > 0) {
+        int keep_box_index = boxIndex[0];
+        keep[num_to_keep++] = keep_box_index;
+
+        boxIndex.erase(boxIndex.begin());
+
+        for (auto it = boxIndex.begin(); it != boxIndex.end(); ) {
+            float iou_bev_v = iou_bev(boxes_data + keep_box_index * 7, boxes_data + (*it) * 7);
+            if (iou_bev_v > nms_overlap_thresh) {
+                it = boxIndex.erase(it);
+            } else {
+                it++;
+            }
+        }
+    }
+    return num_to_keep;
+}
diff --git a/pcdet/ops/iou3d_nms/src/iou3d_cpu.h b/pcdet/ops/iou3d_nms/src/iou3d_cpu.h
index 4d93bb6..1dbdb36 100644
--- a/pcdet/ops/iou3d_nms/src/iou3d_cpu.h
+++ b/pcdet/ops/iou3d_nms/src/iou3d_cpu.h
@@ -3,9 +3,8 @@
 
 #include <torch/serialize/tensor.h>
 #include <vector>
-#include <cuda.h>
-#include <cuda_runtime_api.h>
 
 int boxes_iou_bev_cpu(at::Tensor boxes_a_tensor, at::Tensor boxes_b_tensor, at::Tensor ans_iou_tensor);
 int boxes_aligned_iou_bev_cpu(at::Tensor boxes_a_tensor, at::Tensor boxes_b_tensor, at::Tensor ans_iou_tensor);
+int nms_cpu(at::Tensor boxes, at::Tensor keep, float nms_overlap_thresh);
 #endif
diff --git a/pcdet/ops/iou3d_nms/src/iou3d_nms_api.cpp b/pcdet/ops/iou3d_nms/src/iou3d_nms_api.cpp
index 972b55b..a0c416f 100644
--- a/pcdet/ops/iou3d_nms/src/iou3d_nms_api.cpp
+++ b/pcdet/ops/iou3d_nms/src/iou3d_nms_api.cpp
@@ -1,20 +1,12 @@
 #include <torch/serialize/tensor.h>
 #include <torch/extension.h>
 #include <vector>
-#include <cuda.h>
-#include <cuda_runtime_api.h>
 
 #include "iou3d_cpu.h"
-#include "iou3d_nms.h"
 
 
 PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
-    m.def("boxes_aligned_overlap_bev_gpu", &boxes_aligned_overlap_bev_gpu, "aligned oriented boxes overlap");
-	m.def("boxes_overlap_bev_gpu", &boxes_overlap_bev_gpu, "oriented boxes overlap");
-	m.def("paired_boxes_overlap_bev_gpu", &paired_boxes_overlap_bev_gpu, "oriented boxes overlap");
-	m.def("boxes_iou_bev_gpu", &boxes_iou_bev_gpu, "oriented boxes iou");
-	m.def("nms_gpu", &nms_gpu, "oriented nms gpu");
-	m.def("nms_normal_gpu", &nms_normal_gpu, "nms gpu");
 	m.def("boxes_aligned_iou_bev_cpu", &boxes_aligned_iou_bev_cpu, "aligned oriented boxes iou");
 	m.def("boxes_iou_bev_cpu", &boxes_iou_bev_cpu, "oriented boxes iou");
+	m.def("nms_cpu", &nms_cpu, "nms cpu");
 }
diff --git a/pcdet/ops/pointnet2/pointnet2_batch/pointnet2_utils.py b/pcdet/ops/pointnet2/pointnet2_batch/pointnet2_utils.py
index c57afe1..5cc1c33 100644
--- a/pcdet/ops/pointnet2/pointnet2_batch/pointnet2_utils.py
+++ b/pcdet/ops/pointnet2/pointnet2_batch/pointnet2_utils.py
@@ -4,8 +4,6 @@ import torch
 import torch.nn as nn
 from torch.autograd import Function, Variable
 
-from . import pointnet2_batch_cuda as pointnet2
-
 
 class FarthestPointSampling(Function):
     @staticmethod
diff --git a/pcdet/ops/pointnet2/pointnet2_stack/pointnet2_utils.py b/pcdet/ops/pointnet2/pointnet2_stack/pointnet2_utils.py
index cd2c1f3..ae207b9 100644
--- a/pcdet/ops/pointnet2/pointnet2_stack/pointnet2_utils.py
+++ b/pcdet/ops/pointnet2/pointnet2_stack/pointnet2_utils.py
@@ -2,8 +2,6 @@ import torch
 import torch.nn as nn
 from torch.autograd import Function, Variable
 
-from . import pointnet2_stack_cuda as pointnet2
-
 
 class BallQuery(Function):
 
diff --git a/pcdet/ops/pointnet2/pointnet2_stack/voxel_query_utils.py b/pcdet/ops/pointnet2/pointnet2_stack/voxel_query_utils.py
index b22da2d..ae1a52d 100644
--- a/pcdet/ops/pointnet2/pointnet2_stack/voxel_query_utils.py
+++ b/pcdet/ops/pointnet2/pointnet2_stack/voxel_query_utils.py
@@ -4,7 +4,6 @@ from torch.autograd import Function
 import torch.nn as nn
 from typing import List
 
-from . import pointnet2_stack_cuda as pointnet2
 from . import pointnet2_utils
 
 class VoxelQuery(Function):
diff --git a/pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py b/pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py
index d8ca924..304cbb8 100644
--- a/pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py
+++ b/pcdet/ops/roiaware_pool3d/roiaware_pool3d_utils.py
@@ -1,3 +1,5 @@
+# Copyright 2024 Huawei Technologies Co., Ltd
+
 import torch
 import torch.nn as nn
 from torch.autograd import Function
@@ -35,8 +37,8 @@ def points_in_boxes_gpu(points, boxes):
     assert boxes.shape[2] == 7 and points.shape[2] == 3
     batch_size, num_points, _ = points.shape
 
-    box_idxs_of_pts = points.new_zeros((batch_size, num_points), dtype=torch.int).fill_(-1)
-    roiaware_pool3d_cuda.points_in_boxes_gpu(boxes.contiguous(), points.contiguous(), box_idxs_of_pts)
+    import mx_driving.preprocess
+    box_idxs_of_pts = mx_driving.preprocess.npu_points_in_box(boxes.contiguous().npu(), points.contiguous().npu())
 
     return box_idxs_of_pts
 
@@ -87,7 +89,6 @@ class RoIAwarePool3dFunction(Function):
 
         pool_method_map = {'max': 0, 'avg': 1}
         pool_method = pool_method_map[pool_method]
-        roiaware_pool3d_cuda.forward(rois, pts, pts_feature, argmax, pts_idx_of_voxels, pooled_features, pool_method)
 
         ctx.roiaware_pool3d_for_backward = (pts_idx_of_voxels, argmax, pool_method, num_pts, num_channels)
         return pooled_features
@@ -102,7 +103,6 @@ class RoIAwarePool3dFunction(Function):
         pts_idx_of_voxels, argmax, pool_method, num_pts, num_channels = ctx.roiaware_pool3d_for_backward
 
         grad_in = grad_out.new_zeros((num_pts, num_channels))
-        roiaware_pool3d_cuda.backward(pts_idx_of_voxels, argmax, grad_out.contiguous(), grad_in, pool_method)
 
         return None, None, grad_in, None, None, None
 
diff --git a/pcdet/ops/roiaware_pool3d/src/roiaware_pool3d.cpp b/pcdet/ops/roiaware_pool3d/src/roiaware_pool3d.cpp
index 00edfef..2bd89df 100644
--- a/pcdet/ops/roiaware_pool3d/src/roiaware_pool3d.cpp
+++ b/pcdet/ops/roiaware_pool3d/src/roiaware_pool3d.cpp
@@ -15,108 +15,9 @@ All Rights Reserved 2019-2020.
 //#define CHECK_CONTIGUOUS(x) AT_CHECK(x.is_contiguous(), #x, " must be contiguous ")
 //#define CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)
 
-
-void roiaware_pool3d_launcher(int boxes_num, int pts_num, int channels, int max_pts_each_voxel,
-    int out_x, int out_y, int out_z, const float *rois, const float *pts, const float *pts_feature,
-    int *argmax, int *pts_idx_of_voxels, float *pooled_features, int pool_method);
-
-void roiaware_pool3d_backward_launcher(int boxes_num, int out_x, int out_y, int out_z, int channels, int max_pts_each_voxel,
-    const int *pts_idx_of_voxels, const int *argmax, const float *grad_out, float *grad_in, int pool_method);
-
 void points_in_boxes_launcher(int batch_size, int boxes_num, int pts_num, const float *boxes,
     const float *pts, int *box_idx_of_points);
 
-int roiaware_pool3d_gpu(at::Tensor rois, at::Tensor pts, at::Tensor pts_feature, at::Tensor argmax,
-    at::Tensor pts_idx_of_voxels, at::Tensor pooled_features, int pool_method){
-    // params rois: (N, 7) [x, y, z, dx, dy, dz, heading] (x, y, z) is the box center
-    // params pts: (npoints, 3) [x, y, z]
-    // params pts_feature: (npoints, C)
-    // params argmax: (N, out_x, out_y, out_z, C)
-    // params pts_idx_of_voxels: (N, out_x, out_y, out_z, max_pts_each_voxel)
-    // params pooled_features: (N, out_x, out_y, out_z, C)
-    // params pool_method: 0: max_pool 1: avg_pool
-
-//    CHECK_INPUT(rois);
-//    CHECK_INPUT(pts);
-//    CHECK_INPUT(pts_feature);
-//    CHECK_INPUT(argmax);
-//    CHECK_INPUT(pts_idx_of_voxels);
-//    CHECK_INPUT(pooled_features);
-
-    int boxes_num = rois.size(0);
-    int pts_num = pts.size(0);
-    int channels = pts_feature.size(1);
-    int max_pts_each_voxel = pts_idx_of_voxels.size(4);  // index 0 is the counter
-    int out_x = pts_idx_of_voxels.size(1);
-    int out_y = pts_idx_of_voxels.size(2);
-    int out_z = pts_idx_of_voxels.size(3);
-    assert ((out_x < 256) && (out_y < 256) && (out_z < 256));  // we encode index with 8bit
-
-    const float *rois_data = rois.data<float>();
-    const float *pts_data = pts.data<float>();
-    const float *pts_feature_data = pts_feature.data<float>();
-    int *argmax_data = argmax.data<int>();
-    int *pts_idx_of_voxels_data = pts_idx_of_voxels.data<int>();
-    float *pooled_features_data = pooled_features.data<float>();
-
-    roiaware_pool3d_launcher(boxes_num, pts_num, channels, max_pts_each_voxel, out_x, out_y, out_z,
-        rois_data, pts_data, pts_feature_data, argmax_data, pts_idx_of_voxels_data, pooled_features_data, pool_method);
-
-    return 1;
-}
-
-int roiaware_pool3d_gpu_backward(at::Tensor pts_idx_of_voxels, at::Tensor argmax, at::Tensor grad_out, at::Tensor grad_in, int pool_method){
-    // params pts_idx_of_voxels: (N, out_x, out_y, out_z, max_pts_each_voxel)
-    // params argmax: (N, out_x, out_y, out_z, C)
-    // params grad_out: (N, out_x, out_y, out_z, C)
-    // params grad_in: (npoints, C), return value
-    // params pool_method: 0: max_pool 1: avg_pool
-
-//    CHECK_INPUT(pts_idx_of_voxels);
-//    CHECK_INPUT(argmax);
-//    CHECK_INPUT(grad_out);
-//    CHECK_INPUT(grad_in);
-
-    int boxes_num = pts_idx_of_voxels.size(0);
-    int out_x = pts_idx_of_voxels.size(1);
-    int out_y = pts_idx_of_voxels.size(2);
-    int out_z = pts_idx_of_voxels.size(3);
-    int max_pts_each_voxel = pts_idx_of_voxels.size(4);  // index 0 is the counter
-    int channels = grad_out.size(4);
-
-    const int *pts_idx_of_voxels_data = pts_idx_of_voxels.data<int>();
-    const int *argmax_data = argmax.data<int>();
-    const float *grad_out_data = grad_out.data<float>();
-    float *grad_in_data = grad_in.data<float>();
-
-    roiaware_pool3d_backward_launcher(boxes_num, out_x, out_y, out_z, channels, max_pts_each_voxel,
-        pts_idx_of_voxels_data, argmax_data, grad_out_data, grad_in_data, pool_method);
-
-    return 1;
-}
-
-int points_in_boxes_gpu(at::Tensor boxes_tensor, at::Tensor pts_tensor, at::Tensor box_idx_of_points_tensor){
-    // params boxes: (B, N, 7) [x, y, z, dx, dy, dz, heading] (x, y, z) is the box center
-    // params pts: (B, npoints, 3) [x, y, z]
-    // params boxes_idx_of_points: (B, npoints), default -1
-
-//    CHECK_INPUT(boxes_tensor);
-//    CHECK_INPUT(pts_tensor);
-//    CHECK_INPUT(box_idx_of_points_tensor);
-
-    int batch_size = boxes_tensor.size(0);
-    int boxes_num = boxes_tensor.size(1);
-    int pts_num = pts_tensor.size(1);
-
-    const float *boxes = boxes_tensor.data<float>();
-    const float *pts = pts_tensor.data<float>();
-    int *box_idx_of_points = box_idx_of_points_tensor.data<int>();
-
-    points_in_boxes_launcher(batch_size, boxes_num, pts_num, boxes, pts, box_idx_of_points);
-
-    return 1;
-}
-
 
 inline void lidar_to_local_coords_cpu(float shift_x, float shift_y, float rot_angle, float &local_x, float &local_y){
     float cosa = cos(-rot_angle), sina = sin(-rot_angle);
@@ -170,8 +71,5 @@ int points_in_boxes_cpu(at::Tensor boxes_tensor, at::Tensor pts_tensor, at::Tens
 
 
 PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
-    m.def("forward", &roiaware_pool3d_gpu, "roiaware pool3d forward (CUDA)");
-    m.def("backward", &roiaware_pool3d_gpu_backward, "roiaware pool3d backward (CUDA)");
-    m.def("points_in_boxes_gpu", &points_in_boxes_gpu, "points_in_boxes_gpu forward (CUDA)");
     m.def("points_in_boxes_cpu", &points_in_boxes_cpu, "points_in_boxes_cpu forward (CUDA)");
 }
diff --git a/pcdet/ops/roipoint_pool3d/roipoint_pool3d_utils.py b/pcdet/ops/roipoint_pool3d/roipoint_pool3d_utils.py
index 1e13396..47a9cb4 100644
--- a/pcdet/ops/roipoint_pool3d/roipoint_pool3d_utils.py
+++ b/pcdet/ops/roipoint_pool3d/roipoint_pool3d_utils.py
@@ -3,7 +3,6 @@ import torch.nn as nn
 from torch.autograd import Function
 
 from ...utils import box_utils
-from . import roipoint_pool3d_cuda
 
 
 class RoIPointPool3d(nn.Module):
diff --git a/pcdet/utils/common_utils.py b/pcdet/utils/common_utils.py
index af70728..a9c0d9a 100644
--- a/pcdet/utils/common_utils.py
+++ b/pcdet/utils/common_utils.py
@@ -185,10 +185,10 @@ def init_dist_slurm(tcp_port, local_rank, backend='nccl'):
     rank = dist.get_rank()
     return total_gpus, rank
 
-
+    
 def init_dist_pytorch(tcp_port, local_rank, backend='nccl'):
     if mp.get_start_method(allow_none=True) is None:
-        mp.set_start_method('spawn')
+        mp.set_start_method('fork')
     # os.environ['MASTER_PORT'] = str(tcp_port)
     # os.environ['MASTER_ADDR'] = 'localhost'
     num_gpus = torch.cuda.device_count()
diff --git a/pcdet/utils/spconv_utils.py b/pcdet/utils/spconv_utils.py
index c38f899..cba5688 100644
--- a/pcdet/utils/spconv_utils.py
+++ b/pcdet/utils/spconv_utils.py
@@ -20,9 +20,8 @@ def find_all_spconv_keys(model: nn.Module, prefix="") -> Set[str]:
     for name, child in model.named_children():
         new_prefix = f"{prefix}.{name}" if prefix != "" else name
 
-        if isinstance(child, spconv.conv.SparseConvolution):
-            new_prefix = f"{new_prefix}.weight"
-            found_keys.add(new_prefix)
+        new_prefix = f"{new_prefix}.weight"
+        found_keys.add(new_prefix)
 
         found_keys.update(find_all_spconv_keys(child, prefix=new_prefix))
 
diff --git a/requirements.txt b/requirements.txt
index a730fd7..88a4b98 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,13 +1,17 @@
 numpy
 llvmlite
 numba
-torch>=1.1
 tensorboardX
 easydict
 pyyaml
 scikit-image
 tqdm
-torchvision
+torchvision==0.16.0
 SharedArray
 opencv-python
-pyquaternion
\ No newline at end of file
+pyquaternion
+pccm==0.3.4
+torch_scatter==2.1.1
+opencv-python-headless
+av2
+kornia==0.6.5
\ No newline at end of file
diff --git a/setup.py b/setup.py
index f5a31d9..784296c 100644
--- a/setup.py
+++ b/setup.py
@@ -2,7 +2,7 @@ import os
 import subprocess
 
 from setuptools import find_packages, setup
-from torch.utils.cpp_extension import BuildExtension, CUDAExtension
+from torch.utils.cpp_extension import BuildExtension, CUDAExtension, CppExtension
 
 
 def get_git_commit_number():
@@ -21,6 +21,16 @@ def make_cuda_ext(name, module, sources):
     )
     return cuda_ext
 
+def make_cpp_ext(name, module, sources):
+    sources_path = [os.path.join(*module.split('.'), src) for src in sources]
+    for _path in sources_path:
+        if not os.path.exists(_path):
+            raise FileNotFoundError(f"{_path} not exists!")
+    cpp_ext = CppExtension(
+        name=f'{module}.{name}',
+        sources=sources_path
+    )
+    return cpp_ext
 
 def write_version_to_file(version, target_file):
     with open(target_file, 'w') as f:
@@ -56,82 +66,20 @@ if __name__ == '__main__':
             'build_ext': BuildExtension,
         },
         ext_modules=[
-            make_cuda_ext(
-                name='iou3d_nms_cuda',
-                module='pcdet.ops.iou3d_nms',
-                sources=[
-                    'src/iou3d_cpu.cpp',
-                    'src/iou3d_nms_api.cpp',
-                    'src/iou3d_nms.cpp',
-                    'src/iou3d_nms_kernel.cu',
-                ]
-            ),
-            make_cuda_ext(
+            make_cpp_ext(
                 name='roiaware_pool3d_cuda',
                 module='pcdet.ops.roiaware_pool3d',
                 sources=[
                     'src/roiaware_pool3d.cpp',
-                    'src/roiaware_pool3d_kernel.cu',
                 ]
             ),
-            make_cuda_ext(
-                name='roipoint_pool3d_cuda',
-                module='pcdet.ops.roipoint_pool3d',
-                sources=[
-                    'src/roipoint_pool3d.cpp',
-                    'src/roipoint_pool3d_kernel.cu',
-                ]
-            ),
-            make_cuda_ext(
-                name='pointnet2_stack_cuda',
-                module='pcdet.ops.pointnet2.pointnet2_stack',
-                sources=[
-                    'src/pointnet2_api.cpp',
-                    'src/ball_query.cpp',
-                    'src/ball_query_gpu.cu',
-                    'src/group_points.cpp',
-                    'src/group_points_gpu.cu',
-                    'src/sampling.cpp',
-                    'src/sampling_gpu.cu', 
-                    'src/interpolate.cpp', 
-                    'src/interpolate_gpu.cu',
-                    'src/voxel_query.cpp', 
-                    'src/voxel_query_gpu.cu',
-                    'src/vector_pool.cpp',
-                    'src/vector_pool_gpu.cu'
-                ],
-            ),
-            make_cuda_ext(
-                name='pointnet2_batch_cuda',
-                module='pcdet.ops.pointnet2.pointnet2_batch',
-                sources=[
-                    'src/pointnet2_api.cpp',
-                    'src/ball_query.cpp',
-                    'src/ball_query_gpu.cu',
-                    'src/group_points.cpp',
-                    'src/group_points_gpu.cu',
-                    'src/interpolate.cpp',
-                    'src/interpolate_gpu.cu',
-                    'src/sampling.cpp',
-                    'src/sampling_gpu.cu',
-
-                ],
-            ),
-            make_cuda_ext(
-                name="bev_pool_ext",
-                module="pcdet.ops.bev_pool",
-                sources=[
-                    "src/bev_pool.cpp",
-                    "src/bev_pool_cuda.cu",
-                ],
-            ),
-            make_cuda_ext(
-                name='ingroup_inds_cuda',
-                module='pcdet.ops.ingroup_inds',
+            make_cpp_ext(
+                name='iou3d_nms_cuda', 
+                module='pcdet.ops.iou3d_nms',
                 sources=[
-                    'src/ingroup_inds.cpp',
-                    'src/ingroup_inds_kernel.cu',
+                    'src/iou3d_cpu.cpp',
+                    'src/iou3d_nms_api.cpp',
                 ]
-            ),
+            )
         ],
     )
diff --git a/third_party_patches/spconv_patches/spconv/core_cc/csrc/sparse/all/__init__.pyi b/third_party_patches/spconv_patches/spconv/core_cc/csrc/sparse/all/__init__.pyi
new file mode 100644
index 0000000..ce4439c
--- /dev/null
+++ b/third_party_patches/spconv_patches/spconv/core_cc/csrc/sparse/all/__init__.pyi
@@ -0,0 +1,104 @@
+from typing import overload, Any, Callable, Dict, List, Optional, Set, Tuple, Type, Union
+from pccm.stubs import EnumValue, EnumClassValue
+from cumm.tensorview import Tensor
+class ThrustCustomAllocatorV2:
+    alloc_func: Callable[int, int]
+class SpconvOps:
+    @staticmethod
+    def generate_conv_inds_cpu(indices: Tensor, indice_pairs: Tensor, out_inds: Tensor, indice_num_per_loc: Tensor, batch_size: int, output_dims: List[int], input_dims: List[int], ksize: List[int], stride: List[int], padding: List[int], dilation: List[int], transposed: bool = False) -> int: 
+        """
+        Args:
+            indices: 
+            indice_pairs: 
+            out_inds: 
+            indice_num_per_loc: 
+            batch_size: 
+            output_dims: 
+            input_dims: 
+            ksize: 
+            stride: 
+            padding: 
+            dilation: 
+            transposed: 
+        """
+        ...
+    @staticmethod
+    def generate_subm_conv_inds_cpu(indices: Tensor, indice_pairs: Tensor, out_inds: Tensor, indice_num_per_loc: Tensor, batch_size: int, input_dims: List[int], ksize: List[int], dilation: List[int]) -> int: 
+        """
+        Args:
+            indices: 
+            indice_pairs: 
+            out_inds: 
+            indice_num_per_loc: 
+            batch_size: 
+            input_dims: 
+            ksize: 
+            dilation: 
+        """
+        ...
+    @staticmethod
+    def maxpool_forward_cpu(out: Tensor, inp: Tensor, out_inds: Tensor, in_inds: Tensor) -> None: 
+        """
+        Args:
+            out: 
+            inp: 
+            out_inds: 
+            in_inds: 
+        """
+        ...
+    @staticmethod
+    def maxpool_backward_cpu(out: Tensor, inp: Tensor, dout: Tensor, dinp: Tensor, out_inds: Tensor, in_inds: Tensor) -> None: 
+        """
+        Args:
+            out: 
+            inp: 
+            dout: 
+            dinp: 
+            out_inds: 
+            in_inds: 
+        """
+        ...
+    @staticmethod
+    def gather_cpu(out: Tensor, inp: Tensor, inds: Tensor) -> None: 
+        """
+        Args:
+            out: 
+            inp: 
+            inds: 
+        """
+        ...
+    @staticmethod
+    def scatter_add_cpu(out: Tensor, inp: Tensor, inds: Tensor) -> None: 
+        """
+        Args:
+            out: 
+            inp: 
+            inds: 
+        """
+        ...
+    @staticmethod
+    def calc_point2voxel_meta_data(vsize_xyz: List[float], coors_range_xyz: List[float]) -> Tuple[List[float], List[int], List[int], List[float]]: 
+        """
+        Args:
+            vsize_xyz: 
+            coors_range_xyz: 
+        """
+        ...
+    @staticmethod
+    def point2voxel_cpu(points: Tensor, voxels: Tensor, indices: Tensor, num_per_voxel: Tensor, densehashdata: Tensor, pc_voxel_id: Tensor, vsize: List[float], grid_size: List[int], grid_stride: List[int], coors_range: List[float], empty_mean: bool = False, clear_voxels: bool = True) -> Tuple[Tensor, Tensor, Tensor]: 
+        """
+        Args:
+            points: 
+            voxels: 
+            indices: 
+            num_per_voxel: 
+            densehashdata: 
+            pc_voxel_id: 
+            vsize: 
+            grid_size: 
+            grid_stride: 
+            coors_range: 
+            empty_mean: 
+            clear_voxels: 
+        """
+        ...
diff --git a/tools/cfgs/nuscenes_models/cbgs_dyn_pp_centerpoint.yaml b/tools/cfgs/nuscenes_models/cbgs_dyn_pp_centerpoint.yaml
index 51d6c7b..24e3fe5 100644
--- a/tools/cfgs/nuscenes_models/cbgs_dyn_pp_centerpoint.yaml
+++ b/tools/cfgs/nuscenes_models/cbgs_dyn_pp_centerpoint.yaml
@@ -15,18 +15,23 @@ DATA_CONFIG:
                 'test': True
             }
 
-        -   NAME: transform_points_to_voxels_placeholder
+        -   NAME: transform_points_to_voxels
             VOXEL_SIZE: [0.2, 0.2, 8.0]
+            MAX_POINTS_PER_VOXEL: 20
+            MAX_NUMBER_OF_VOXELS: {
+                'train': 30000,
+                'test': 30000
+            }
 
 MODEL:
     NAME: CenterPoint
 
     VFE:
-        NAME: DynPillarVFE
+        NAME: PillarVFE
         WITH_DISTANCE: False
         USE_ABSLOTE_XYZ: True
         USE_NORM: True
-        NUM_FILTERS: [ 64, 64 ]
+        NUM_FILTERS: [ 64 ]
 
     MAP_TO_BEV:
         NAME: PointPillarScatter
@@ -45,7 +50,7 @@ MODEL:
         CLASS_AGNOSTIC: False
 
         CLASS_NAMES_EACH_HEAD: [
-            ['car'], 
+            ['car'],
             ['truck', 'construction_vehicle'],
             ['bus', 'trailer'],
             ['barrier'],
@@ -96,11 +101,11 @@ MODEL:
 
 
 OPTIMIZATION:
-    BATCH_SIZE_PER_GPU: 4
+    BATCH_SIZE_PER_GPU: 12
     NUM_EPOCHS: 20
 
     OPTIMIZER: adam_onecycle
-    LR: 0.001
+    LR: 0.003
     WEIGHT_DECAY: 0.01
     MOMENTUM: 0.9
 
diff --git a/tools/cfgs/nuscenes_models/cbgs_dyn_pp_centerpoint_performance.yaml b/tools/cfgs/nuscenes_models/cbgs_dyn_pp_centerpoint_performance.yaml
new file mode 100644
index 0000000..f801449
--- /dev/null
+++ b/tools/cfgs/nuscenes_models/cbgs_dyn_pp_centerpoint_performance.yaml
@@ -0,0 +1,122 @@
+CLASS_NAMES: ['car','truck', 'construction_vehicle', 'bus', 'trailer',
+              'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']
+
+DATA_CONFIG:
+    _BASE_CONFIG_: cfgs/dataset_configs/nuscenes_dataset.yaml
+
+    POINT_CLOUD_RANGE: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
+    DATA_PROCESSOR:
+        -   NAME: mask_points_and_boxes_outside_range
+            REMOVE_OUTSIDE_BOXES: True
+
+        -   NAME: shuffle_points
+            SHUFFLE_ENABLED: {
+                'train': True,
+                'test': True
+            }
+
+        -   NAME: transform_points_to_voxels
+            VOXEL_SIZE: [0.2, 0.2, 8.0]
+            MAX_POINTS_PER_VOXEL: 20
+            MAX_NUMBER_OF_VOXELS: {
+                'train': 30000,
+                'test': 30000
+            }
+
+MODEL:
+    NAME: CenterPoint
+
+    VFE:
+        NAME: PillarVFE
+        WITH_DISTANCE: False
+        USE_ABSLOTE_XYZ: True
+        USE_NORM: True
+        NUM_FILTERS: [ 64 ]
+
+    MAP_TO_BEV:
+        NAME: PointPillarScatter
+        NUM_BEV_FEATURES: 64
+
+    BACKBONE_2D:
+        NAME: BaseBEVBackbone
+        LAYER_NUMS: [3, 5, 5]
+        LAYER_STRIDES: [2, 2, 2]
+        NUM_FILTERS: [64, 128, 256]
+        UPSAMPLE_STRIDES: [0.5, 1, 2]
+        NUM_UPSAMPLE_FILTERS: [128, 128, 128]
+
+    DENSE_HEAD:
+        NAME: CenterHead
+        CLASS_AGNOSTIC: False
+
+        CLASS_NAMES_EACH_HEAD: [
+            ['car'],
+            ['truck', 'construction_vehicle'],
+            ['bus', 'trailer'],
+            ['barrier'],
+            ['motorcycle', 'bicycle'],
+            ['pedestrian', 'traffic_cone'],
+        ]
+
+        SHARED_CONV_CHANNEL: 64
+        USE_BIAS_BEFORE_NORM: True
+        NUM_HM_CONV: 2
+        SEPARATE_HEAD_CFG:
+            HEAD_ORDER: ['center', 'center_z', 'dim', 'rot', 'vel']
+            HEAD_DICT: {
+                'center': {'out_channels': 2, 'num_conv': 2},
+                'center_z': {'out_channels': 1, 'num_conv': 2},
+                'dim': {'out_channels': 3, 'num_conv': 2},
+                'rot': {'out_channels': 2, 'num_conv': 2},
+                'vel': {'out_channels': 2, 'num_conv': 2},
+            }
+
+        TARGET_ASSIGNER_CONFIG:
+            FEATURE_MAP_STRIDE: 4
+            NUM_MAX_OBJS: 500
+            GAUSSIAN_OVERLAP: 0.1
+            MIN_RADIUS: 2
+
+        LOSS_CONFIG:
+            LOSS_WEIGHTS: {
+                'cls_weight': 1.0,
+                'loc_weight': 0.25,
+                'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0, 1.0]
+            }
+
+        POST_PROCESSING:
+            SCORE_THRESH: 0.1
+            POST_CENTER_LIMIT_RANGE: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
+            MAX_OBJ_PER_SAMPLE: 500
+            NMS_CONFIG:
+                NMS_TYPE: nms_gpu
+                NMS_THRESH: 0.2
+                NMS_PRE_MAXSIZE: 1000
+                NMS_POST_MAXSIZE: 83
+
+    POST_PROCESSING:
+        RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
+
+        EVAL_METRIC: kitti
+
+
+OPTIMIZATION:
+    BATCH_SIZE_PER_GPU: 12
+    NUM_EPOCHS: 1
+
+    OPTIMIZER: adam_onecycle
+    LR: 0.003
+    WEIGHT_DECAY: 0.01
+    MOMENTUM: 0.9
+
+    MOMS: [0.95, 0.85]
+    PCT_START: 0.4
+    DIV_FACTOR: 10
+    DECAY_STEP_LIST: [35, 45]
+    LR_DECAY: 0.1
+    LR_CLIP: 0.0000001
+
+    LR_WARMUP: False
+    WARMUP_EPOCH: 1
+
+    GRAD_NORM_CLIP: 10
diff --git a/tools/test.py b/tools/test.py
index 51b7178..cd8652d 100644
--- a/tools/test.py
+++ b/tools/test.py
@@ -9,6 +9,8 @@ from pathlib import Path
 
 import numpy as np
 import torch
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 from tensorboardX import SummaryWriter
 
 from eval_utils import eval_utils
@@ -29,7 +31,7 @@ def parse_config():
     parser.add_argument('--pretrained_model', type=str, default=None, help='pretrained_model')
     parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')
     parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')
-    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')
+    parser.add_argument('--local-rank', type=int, default=0, help='local rank for distributed training')
     parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,
                         help='set extra config keys if needed')
 
diff --git a/tools/train.py b/tools/train.py
index 29a88bd..8733edc 100644
--- a/tools/train.py
+++ b/tools/train.py
@@ -7,6 +7,8 @@ from pathlib import Path
 from test import repeat_eval_ckpt
 
 import torch
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 import torch.nn as nn
 from tensorboardX import SummaryWriter
 
@@ -33,7 +35,7 @@ def parse_config():
     parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')
     parser.add_argument('--fix_random_seed', action='store_true', default=False, help='')
     parser.add_argument('--ckpt_save_interval', type=int, default=1, help='number of training epochs')
-    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')
+    parser.add_argument('--local-rank', type=int, default=0, help='local rank for distributed training')
     parser.add_argument('--max_ckpt_save_num', type=int, default=30, help='max number of saved checkpoint')
     parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')
     parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,
@@ -108,7 +110,7 @@ def main():
     for key, val in vars(args).items():
         logger.info('{:16} {}'.format(key, val))
     log_config_to_file(cfg, logger=logger)
-    if cfg.LOCAL_RANK == 0:
+    if cfg.LOCAL_RANK == 0 and os.path.exists(args.cfg_file) and os.path.exists(output_dir):
         os.system('cp %s %s' % (args.cfg_file, output_dir))
 
     tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None
diff --git a/tools/train_utils/train_utils.py b/tools/train_utils/train_utils.py
index 04071fb..56a0257 100644
--- a/tools/train_utils/train_utils.py
+++ b/tools/train_utils/train_utils.py
@@ -116,10 +116,6 @@ def train_one_epoch(model, optimizer, train_loader, model_func, lr_scheduler, ac
                             )
                     )
                     
-                    if show_gpu_stat and accumulated_iter % (3 * logger_iter_interval) == 0:
-                        # To show the GPU utilization, please install gpustat through "pip install gpustat"
-                        gpu_info = os.popen('gpustat').read()
-                        logger.info(gpu_info)
             else:                
                 pbar.update()
                 pbar.set_postfix(dict(total_it=accumulated_iter))
