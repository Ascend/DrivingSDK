diff --git a/src/lerobot/configs/train.py b/src/lerobot/configs/train.py
index 2f3a65db..8c20f399 100644
--- a/src/lerobot/configs/train.py
+++ b/src/lerobot/configs/train.py
@@ -51,7 +51,7 @@ class TrainPipelineConfig(HubMixin):
     # AND for the evaluation environments.
     seed: int | None = 1000
     # Number of workers for the dataloader.
-    num_workers: int = 4
+    num_workers: int = 12
     batch_size: int = 8
     steps: int = 100_000
     eval_freq: int = 20_000
diff --git a/src/lerobot/datasets/utils.py b/src/lerobot/datasets/utils.py
index 37d8432b..3c1f4f0f 100644
--- a/src/lerobot/datasets/utils.py
+++ b/src/lerobot/datasets/utils.py
@@ -23,6 +23,7 @@ from pathlib import Path
 from pprint import pformat
 from typing import Any, Generic, TypeVar
 
+import itertools
 import datasets
 import numpy as np
 import packaging.version
@@ -892,12 +893,7 @@ def cycle(iterable: Any) -> Iterator[Any]:
     Yields:
         Items from the iterable, restarting from the beginning when exhausted.
     """
-    iterator = iter(iterable)
-    while True:
-        try:
-            yield next(iterator)
-        except StopIteration:
-            iterator = iter(iterable)
+    return itertools.cycle(iterable)
 
 
 def create_branch(repo_id: str, *, branch: str, repo_type: str | None = None) -> None:
diff --git a/src/lerobot/optim/optimizers.py b/src/lerobot/optim/optimizers.py
index f2bd0df4..e6d1ee19 100644
--- a/src/lerobot/optim/optimizers.py
+++ b/src/lerobot/optim/optimizers.py
@@ -21,6 +21,7 @@ from typing import Any
 import draccus
 import torch
 from safetensors.torch import load_file, save_file
+from mindspeed.optimizer.adamw import AdamW
 
 from lerobot.datasets.utils import flatten_dict, unflatten_dict, write_json
 from lerobot.utils.constants import (
@@ -85,7 +86,7 @@ class AdamWConfig(OptimizerConfig):
     def build(self, params: dict) -> torch.optim.Optimizer:
         kwargs = asdict(self)
         kwargs.pop("grad_clip_norm")
-        return torch.optim.AdamW(params, **kwargs)
+        return AdamW(params, **kwargs)
 
 
 @OptimizerConfig.register_subclass("sgd")
diff --git a/src/lerobot/policies/act/modeling_act.py b/src/lerobot/policies/act/modeling_act.py
index b7cbcd06..6591cd9a 100644
--- a/src/lerobot/policies/act/modeling_act.py
+++ b/src/lerobot/policies/act/modeling_act.py
@@ -551,8 +551,7 @@ class ACTEncoderLayer(nn.Module):
         if self.pre_norm:
             x = self.norm1(x)
         q = k = x if pos_embed is None else x + pos_embed
-        x = self.self_attn(q, k, value=x, key_padding_mask=key_padding_mask)
-        x = x[0]  # note: [0] to select just the output, not the attention weights
+        x = self.self_attn(q, k, value=x, key_padding_mask=key_padding_mask, need_weights=False)[0]
         x = skip + self.dropout1(x)
         if self.pre_norm:
             skip = x
@@ -635,7 +634,7 @@ class ACTDecoderLayer(nn.Module):
         if self.pre_norm:
             x = self.norm1(x)
         q = k = self.maybe_add_pos_embed(x, decoder_pos_embed)
-        x = self.self_attn(q, k, value=x)[0]  # select just the output, not the attention weights
+        x = self.self_attn(q, k, value=x, need_weights=False)[0]
         x = skip + self.dropout1(x)
         if self.pre_norm:
             skip = x
@@ -647,6 +646,7 @@ class ACTDecoderLayer(nn.Module):
             query=self.maybe_add_pos_embed(x, decoder_pos_embed),
             key=self.maybe_add_pos_embed(encoder_out, encoder_pos_embed),
             value=encoder_out,
+            need_weights=False
         )[0]  # select just the output, not the attention weights
         x = skip + self.dropout2(x)
         if self.pre_norm:
diff --git a/src/lerobot/scripts/lerobot_train.py b/src/lerobot/scripts/lerobot_train.py
index 84eb81ad..02a4e721 100644
--- a/src/lerobot/scripts/lerobot_train.py
+++ b/src/lerobot/scripts/lerobot_train.py
@@ -20,6 +20,8 @@ from pprint import pformat
 from typing import Any
 
 import torch
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 from accelerate import Accelerator
 from termcolor import colored
 from torch.optim import Optimizer
@@ -149,7 +151,7 @@ def train(cfg: TrainPipelineConfig, accelerator: Accelerator | None = None):
     if accelerator is None:
         from accelerate.utils import DistributedDataParallelKwargs
 
-        ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)
+        ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=False, gradient_as_bucket_view=True)
         accelerator = Accelerator(step_scheduler_with_optimizer=False, kwargs_handlers=[ddp_kwargs])
 
     init_logging(accelerator=accelerator)
@@ -280,12 +282,13 @@ def train(cfg: TrainPipelineConfig, accelerator: Accelerator | None = None):
     dataloader = torch.utils.data.DataLoader(
         dataset,
         num_workers=cfg.num_workers,
+        persistent_workers=True,
         batch_size=cfg.batch_size,
         shuffle=shuffle and not cfg.dataset.streaming,
         sampler=sampler,
-        pin_memory=device.type == "cuda",
+        pin_memory=True,
         drop_last=False,
-        prefetch_factor=2 if cfg.num_workers > 0 else None,
+        prefetch_factor=4 if cfg.num_workers > 0 else None,
     )
 
     # Prepare everything with accelerator
