diff --git a/mmdet3d/__init__.py b/mmdet3d/__init__.py
index 643c39c..001b224 100644
--- a/mmdet3d/__init__.py
+++ b/mmdet3d/__init__.py
@@ -19,7 +19,7 @@ def digit_version(version_str):
 
 
 mmcv_minimum_version = '1.5.2'
-mmcv_maximum_version = '1.7.0'
+mmcv_maximum_version = '1.7.2'
 mmcv_version = digit_version(mmcv.__version__)
 
 
diff --git a/mmdet3d/apis/train.py b/mmdet3d/apis/train.py
index 4d97026..be10ecd 100644
--- a/mmdet3d/apis/train.py
+++ b/mmdet3d/apis/train.py
@@ -4,7 +4,7 @@ import warnings
 
 import numpy as np
 import torch
-from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
+from mmcv.device.npu import NPUDataParallel, NPUDistributedDataParallel
 from mmcv.runner import (HOOKS, DistSamplerSeedHook, EpochBasedRunner,
                          Fp16OptimizerHook, OptimizerHook, build_optimizer,
                          build_runner, get_dist_info)
@@ -103,13 +103,13 @@ def train_segmentor(model,
         find_unused_parameters = cfg.get('find_unused_parameters', False)
         # Sets the `find_unused_parameters` parameter in
         # torch.nn.parallel.DistributedDataParallel
-        model = MMDistributedDataParallel(
+        model = NPUDistributedDataParallel(
             model.cuda(),
             device_ids=[torch.cuda.current_device()],
             broadcast_buffers=False,
             find_unused_parameters=find_unused_parameters)
     else:
-        model = MMDataParallel(
+        model = NPUDataParallel(
             model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)
 
     # build runner
@@ -223,13 +223,13 @@ def train_detector(model,
         find_unused_parameters = cfg.get('find_unused_parameters', False)
         # Sets the `find_unused_parameters` parameter in
         # torch.nn.parallel.DistributedDataParallel
-        model = MMDistributedDataParallel(
+        model = NPUDistributedDataParallel(
             model.cuda(),
             device_ids=[torch.cuda.current_device()],
             broadcast_buffers=False,
             find_unused_parameters=find_unused_parameters)
     else:
-        model = MMDataParallel(
+        model = NPUDataParallel(
             model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)
 
     # build runner
diff --git a/mmdet3d/models/model_utils/spatial_cross_attention.py b/mmdet3d/models/model_utils/spatial_cross_attention.py
index 22dabac..c629cf2 100644
--- a/mmdet3d/models/model_utils/spatial_cross_attention.py
+++ b/mmdet3d/models/model_utils/spatial_cross_attention.py
@@ -23,6 +23,7 @@ from .multi_scale_deformable_attn_function import MultiScaleDeformableAttnFuncti
 
 ext_module = ext_loader.load_ext(
     '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])
+import mx_driving
 
 
 @TRANSFORMER_LAYER_SEQUENCE.register_module()
@@ -87,17 +88,16 @@ class SpatialDecoder(TransformerLayerSequence):
         eps = 1e-5
         ogfH, ogfW = self.final_dim
         reference_points = reference_points[None, None].repeat(B, N, 1, 1, 1, 1)
-        reference_points = torch.inverse(bda).view(B, 1, 1, 1, 1, 3,
-                                                   3).matmul(reference_points.unsqueeze(-1)).squeeze(-1)
+        reference_points = torch.inverse(bda).view(B, 1, 3,
+                                                   3).matmul(reference_points.view(B, N * reference_points.shape[2] * reference_points.shape[3] * reference_points.shape[4], 3, 1)).reshape(B, N, reference_points.shape[2], reference_points.shape[3], reference_points.shape[4], 3)
         reference_points -= trans.view(B, N, 1, 1, 1, 3)
         combine = rots.matmul(torch.inverse(intrins)).inverse()
-        reference_points_cam = combine.view(B, N, 1, 1, 1, 3, 3).matmul(reference_points.unsqueeze(-1)).squeeze(-1)
+        reference_points_cam = combine.view(B * N, 1, 1, 1, 3, 3).matmul(reference_points.view(B * N, reference_points.shape[2], reference_points.shape[3], reference_points.shape[4], 3, 1)) \
+                .reshape(B, N, reference_points.shape[2], reference_points.shape[3], reference_points.shape[4], 3)
         reference_points_cam = torch.cat([reference_points_cam[..., 0:2] / torch.maximum(
             reference_points_cam[..., 2:3], torch.ones_like(reference_points_cam[..., 2:3]) * eps),
-                                          reference_points_cam[..., 2:3]], 5
-                                         )
-        reference_points_cam = post_rots.view(B, N, 1, 1, 1, 3, 3).matmul(reference_points_cam.unsqueeze(-1)).squeeze(
-            -1)
+                                          reference_points_cam[..., 2:3]], 5)
+        reference_points_cam = post_rots.reshape(B * N, 1, 1, 1, 3, 3).matmul(reference_points_cam.reshape(B * N, reference_points_cam.shape[2], reference_points_cam.shape[3], reference_points_cam.shape[4], 3, 1)).reshape(B, N, reference_points_cam.shape[2], reference_points_cam.shape[3], reference_points_cam.shape[4], 3)
         reference_points_cam += post_trans.view(B, N, 1, 1, 1, 3)
         reference_points_cam[..., 0] /= ogfW
         reference_points_cam[..., 1] /= ogfH
@@ -661,10 +661,8 @@ class MSDeformableAttention(BaseModule):
                 f' 2 or 4, but get {reference_points.shape[-1]} instead.')
 
         if torch.cuda.is_available() and value.is_cuda:
-
-            output = MultiScaleDeformableAttnFunction_fp32.apply(
-                value, spatial_shapes, level_start_index, sampling_locations,
-                attention_weights, self.im2col_step)
+            output = mx_driving.multi_scale_deformable_attn(value, spatial_shapes, level_start_index,
+                                                        sampling_locations, attention_weights)
         else:
             output = multi_scale_deformable_attn_pytorch(
                 value, spatial_shapes, sampling_locations, attention_weights)
diff --git a/mmdet3d/models/necks/view_transformer.py b/mmdet3d/models/necks/view_transformer.py
index fd692ae..463bffa 100644
--- a/mmdet3d/models/necks/view_transformer.py
+++ b/mmdet3d/models/necks/view_transformer.py
@@ -8,10 +8,9 @@ from mmdet.models.backbones.resnet import BasicBlock
 from torch.cuda.amp.autocast_mode import autocast
 from torch.utils.checkpoint import checkpoint
 
-from mmdet3d.ops.bev_pool_v2.bev_pool import bev_pool_v2
+from mx_driving import bev_pool_v3
 from ..builder import NECKS
 
-
 @NECKS.register_module()
 class LSSViewTransformer(BaseModule):
     r"""Lift-Splat-Shoot view transformer with BEVPoolv2 implementation.
@@ -123,17 +122,15 @@ class LSSViewTransformer(BaseModule):
         # post-transformation
         # B x N x D x H x W x 3
         points = self.frustum.to(rots) - post_trans.view(B, N, 1, 1, 1, 3)
-        points = torch.inverse(post_rots).view(B, N, 1, 1, 1, 3, 3) \
-            .matmul(points.unsqueeze(-1))
+        points = torch.inverse(post_rots).view(B * N, 1, 1, 1, 3, 3).matmul(points.view(B * N, points.shape[2], points.shape[3], points.shape[4], 3, 1)).reshape(B, N, points.shape[2], points.shape[3], points.shape[4], 3, 1)
 
         # cam_to_ego
         points = torch.cat(
             (points[..., :2, :] * points[..., 2:3, :], points[..., 2:3, :]), 5)
         combine = rots.matmul(torch.inverse(cam2imgs))
-        points = combine.view(B, N, 1, 1, 1, 3, 3).matmul(points).squeeze(-1)
-        points += trans.view(B, N, 1, 1, 1, 3)
-        points = bda.view(B, 1, 1, 1, 1, 3,
-                          3).matmul(points.unsqueeze(-1)).squeeze(-1)
+        points = combine.view(B * N, 1, 1, 1, 3, 3).matmul(points.view(B * N, points.shape[2], points.shape[3], points.shape[4], 3, 1)).reshape(B, N, points.shape[2], points.shape[3], points.shape[4], 3)
+        points += trans.view(B, N, 1, 1, 1, 3)  # torch.Size([8, 6, 118, 32, 88, 3])
+        points = torch.matmul(bda.view(B, 1, 3, 3), points.view(B, N * points.shape[2] * points.shape[3] * points.shape[4], 3, 1)).reshape(B, N, points.shape[2], points.shape[3], points.shape[4], 3)
         return points
 
     def init_acceleration_v2(self, coor):
@@ -147,19 +144,15 @@ class LSSViewTransformer(BaseModule):
                 (B, N_cams, D, H, W, C).
         """
 
-        ranks_bev, ranks_depth, ranks_feat, \
-            interval_starts, interval_lengths = \
+        ranks_bev, ranks_depth, ranks_feat = \
             self.voxel_pooling_prepare_v2(coor)
 
         self.ranks_bev = ranks_bev.int().contiguous()
         self.ranks_feat = ranks_feat.int().contiguous()
         self.ranks_depth = ranks_depth.int().contiguous()
-        self.interval_starts = interval_starts.int().contiguous()
-        self.interval_lengths = interval_lengths.int().contiguous()
 
     def voxel_pooling_v2(self, coor, depth, feat):
-        ranks_bev, ranks_depth, ranks_feat, \
-            interval_starts, interval_lengths = \
+        ranks_bev, ranks_depth, ranks_feat = \
             self.voxel_pooling_prepare_v2(coor)
         if ranks_feat is None:
             print('warning ---> no points within the predefined '
@@ -176,9 +169,8 @@ class LSSViewTransformer(BaseModule):
         bev_feat_shape = (depth.shape[0], int(self.grid_size[2]),
                           int(self.grid_size[1]), int(self.grid_size[0]),
                           feat.shape[-1])  # (B, Z, Y, X, C)
-        bev_feat = bev_pool_v2(depth, feat, ranks_depth, ranks_feat, ranks_bev,
-                               bev_feat_shape, interval_starts,
-                               interval_lengths)
+        bev_feat = bev_pool_v3(depth, feat, ranks_depth, ranks_feat, ranks_bev,
+                               bev_feat_shape)
         # collapse Z
         bev_feat = torch.cat(bev_feat.unbind(dim=2), 1)
         return bev_feat
@@ -230,18 +222,8 @@ class LSSViewTransformer(BaseModule):
         ranks_bev, ranks_depth, ranks_feat = \
             ranks_bev[order], ranks_depth[order], ranks_feat[order]
 
-        kept = torch.ones(
-            ranks_bev.shape[0], device=ranks_bev.device, dtype=torch.bool)
-        kept[1:] = ranks_bev[1:] != ranks_bev[:-1]
-        interval_starts = torch.where(kept)[0].int()
-        if len(interval_starts) == 0:
-            return None, None, None, None, None
-        interval_lengths = torch.zeros_like(interval_starts)
-        interval_lengths[:-1] = interval_starts[1:] - interval_starts[:-1]
-        interval_lengths[-1] = ranks_bev.shape[0] - interval_starts[-1]
         return ranks_bev.int().contiguous(), ranks_depth.int().contiguous(
-        ), ranks_feat.int().contiguous(), interval_starts.int().contiguous(
-        ), interval_lengths.int().contiguous()
+        ), ranks_feat.int().contiguous()
 
     def pre_compute(self, input):
         if self.initial_flag:
@@ -260,10 +242,9 @@ class LSSViewTransformer(BaseModule):
             bev_feat_shape = (depth.shape[0], int(self.grid_size[2]),
                               int(self.grid_size[1]), int(self.grid_size[0]),
                               feat.shape[-1])  # (B, Z, Y, X, C)
-            bev_feat = bev_pool_v2(depth, feat, self.ranks_depth,
+            bev_feat = bev_pool_v3(depth, feat, self.ranks_depth,
                                    self.ranks_feat, self.ranks_bev,
-                                   bev_feat_shape, self.interval_starts,
-                                   self.interval_lengths)
+                                   bev_feat_shape)
 
             bev_feat = bev_feat.squeeze(2)
         else:
diff --git a/mmdet3d/ops/bev_pool_v2/bev_pool.py b/mmdet3d/ops/bev_pool_v2/bev_pool.py
index fe16145..1b42443 100644
--- a/mmdet3d/ops/bev_pool_v2/bev_pool.py
+++ b/mmdet3d/ops/bev_pool_v2/bev_pool.py
@@ -3,7 +3,7 @@
 import numpy as np
 import torch
 
-from . import bev_pool_v2_ext
+from mx_driving import bev_pool_v3
 
 __all__ = ['bev_pool_v2', 'TRTBEVPoolv2']
 
@@ -136,9 +136,7 @@ class TRTBEVPoolv2(torch.autograd.Function):
         depth = depth.view(1, n, d, h, w)
         bev_feat_shape = (depth.shape[0], 1, out_height, out_width,
                           feat.shape[-1])  # (B, Z, Y, X, C)
-        bev_feat = bev_pool_v2(depth, feat, ranks_depth, ranks_feat, ranks_bev,
-                               bev_feat_shape, interval_starts,
-                               interval_lengths)
+        bev_feat = bev_pool_v3(depth, feat, ranks_depth, ranks_feat, ranks_bev, bev_feat_shape)
         bev_feat = bev_feat.squeeze(2)
         bev_feat = bev_feat.permute(0, 2, 3, 1)
         return bev_feat
diff --git a/tools/test.py b/tools/test.py
index ad61e21..2894653 100644
--- a/tools/test.py
+++ b/tools/test.py
@@ -7,9 +7,11 @@ import mmcv
 import torch
 from mmcv import Config, DictAction
 from mmcv.cnn import fuse_conv_bn
-from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
+from mmcv.device.npu import NPUDataParallel, NPUDistributedDataParallel
 from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,
                          wrap_fp16_model)
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 
 import mmdet
 from mmdet3d.apis import single_gpu_test
@@ -116,7 +118,7 @@ def parse_args():
         choices=['none', 'pytorch', 'slurm', 'mpi'],
         default='none',
         help='job launcher')
-    parser.add_argument('--local_rank', type=int, default=0)
+    parser.add_argument('--local-rank', type=int, default=0)
     args = parser.parse_args()
     if 'LOCAL_RANK' not in os.environ:
         os.environ['LOCAL_RANK'] = str(args.local_rank)
@@ -233,10 +235,10 @@ def main():
         model.PALETTE = dataset.PALETTE
 
     if not distributed:
-        model = MMDataParallel(model, device_ids=cfg.gpu_ids)
+        model = NPUDataParallel(model, device_ids=cfg.gpu_ids)
         outputs = single_gpu_test(model, data_loader, args.show, args.show_dir)
     else:
-        model = MMDistributedDataParallel(
+        model = NPUDistributedDataParallel(
             model.cuda(),
             device_ids=[torch.cuda.current_device()],
             broadcast_buffers=False)
diff --git a/tools/train.py b/tools/train.py
index ed9c2a6..db2f962 100644
--- a/tools/train.py
+++ b/tools/train.py
@@ -12,6 +12,8 @@ import torch
 import torch.distributed as dist
 from mmcv import Config, DictAction
 from mmcv.runner import get_dist_info, init_dist
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
 
 from mmdet import __version__ as mmdet_version
 from mmdet3d import __version__ as mmdet3d_version
@@ -93,7 +95,7 @@ def parse_args():
         choices=['none', 'pytorch', 'slurm', 'mpi'],
         default='none',
         help='job launcher')
-    parser.add_argument('--local_rank', type=int, default=0)
+    parser.add_argument('--local-rank', type=int, default=0)
     parser.add_argument(
         '--autoscale-lr',
         action='store_true',
